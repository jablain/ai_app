================================================================================
AI-CLI-BRIDGE v2.0.0 - COMPLETE SOURCE CODE DUMP
================================================================================
Generated: Sun Oct 19 10:59:40 AM EDT 2025
Project Root: /home/jacques/dev/ai_app/ai-cli-bridge
================================================================================


################################################################################
# SECTION 1: PROJECT DIRECTORY TREE
################################################################################

.
├── gather_source.sh
├── LaunchCDP.sh
├── overview1.txt
├── overview2.txt
├── src
│   ├── ai_cli_bridge
│   │   ├── ai
│   │   │   ├── base.py
│   │   │   ├── chatgpt.py
│   │   │   ├── claude.py
│   │   │   ├── factory.py
│   │   │   ├── gemini.py
│   │   │   ├── __init__.py
│   │   │   └── web_base.py
│   │   ├── browser_manager.py
│   │   ├── cli.py
│   │   ├── commands
│   │   │   ├── doctor_cmd.py
│   │   │   ├── init_cdp_cmd.py
│   │   │   ├── init_cmd.py
│   │   │   ├── __init__.py
│   │   │   ├── open_cmd.py
│   │   │   ├── send_cmd.py
│   │   │   └── status_cmd.py
│   │   ├── config.py
│   │   ├── daemon
│   │   │   ├── config.py
│   │   │   ├── daemon_cmd.py
│   │   │   ├── __init__.py
│   │   │   ├── main.py
│   │   │   └── process_manager.py
│   │   ├── display.py
│   │   ├── errors.py
│   │   ├── __init__.py
│   │   ├── LaunchCDP.sh
│   │   └── lock_manager.py
│   ├── pyproject.toml
│   ├── README.md
│   └── usermanual.md
├── src.txt
└── StopCDP.sh

5 directories, 36 files


################################################################################
# SECTION 2: SOURCE CODE FILES
################################################################################


================================================================================
FILE: src/ai_cli_bridge/ai/base.py
================================================================================

"""Abstract base class for AI browser automation."""

import asyncio
import time
from abc import ABC, abstractmethod
from typing import Optional, Tuple, Dict, Any, List
from datetime import datetime, timezone

from playwright.async_api import async_playwright, Page, TimeoutError as PWTimeout

class BaseAI(ABC):
    """
    Abstract base class for AI-specific browser automation.
    
    Defines the public interface and common implementation for all AI targets.
    Each concrete AI class (ClaudeAI, ChatGPTAI, etc.) must implement
    the abstract methods with AI-specific logic.
    """
    
    # =========================
    # Class-level configuration
    # =========================
    
    @classmethod
    @abstractmethod
    def get_default_config(cls) -> Dict[str, Any]:
        """
        Get default configuration for this AI.
        
        Returns:
            Dict with ai_target, base_url, cdp port, max_context_tokens, etc.
        """
        pass
    
    
    # =========================
    # Common state (shared by all AIs)
    # =========================
    
    def __init__(self, config: Dict[str, Any]):
        """
        Initialize base AI.
        
        Args:
            config: Config dict with 'ai_target', 'cdp', and 'max_context_tokens' keys
        """
        self._config = config
        self._debug_enabled = False
        self._cdp_url: Optional[str] = None
        self._cdp_source: Optional[str] = None
        self._last_page_url: Optional[str] = None
        
        # Persistent session state
        self._turn_count: int = 0
        self._token_count: int = 0  # Renamed from _token_estimate for clarity
        self._message_count: int = 0
        self._session_start_time: float = time.time()
        self._last_interaction_time: Optional[float] = None
        self._message_history: List[Dict[str, Any]] = []
        
        # CTAW (Current Active Token Window) size from config
        self._ctaw_size: int = config.get("max_context_tokens", 200000)

    # =========================
    # Public interface (Template Method)
    # =========================
    
    async def send_prompt(
        self,
        message: str,
        wait_for_response: bool = True,
        timeout_s: int = 120
    ) -> Tuple[bool, Optional[str], Optional[str], Optional[Dict[str, Any]]]:
        """
        Public method to send a prompt using the Template Method Pattern.
        Handles connection, page selection, and cleanup, then calls the
        subclass-specific implementation.
        """
        ws_url, ws_source = await self._discover_cdp_url()
        if not ws_url:
            self._debug(f"CDP discovery failed: {ws_source}")
            return False, None, None, {"error": "no_cdp", "source": ws_source}
            
        self._debug(f"CDP connected via {ws_source}: {ws_url}")
        
        pw = await async_playwright().start()
        remote = None
        
        try:
            remote = await pw.chromium.connect_over_cdp(ws_url)
            page = await self._pick_page(remote, self.get_base_url())
            
            if not page:
                self._debug("No suitable page found")
                return False, None, None, {"error": "no_page"}
                
            self._last_page_url = page.url
            self._debug(f"Operating on page: {page.url}")
            
            # Call the subclass-specific implementation
            success, snippet, markdown, metadata = await self._execute_interaction(
                page, message, wait_for_response, timeout_s
            )
            
            # --- CENTRALIZED STATE TRACKING ---
            if success:
                # Increment counters
                self._turn_count += 1
                self._message_count += 1
                self._last_interaction_time = time.time()
                
                # Update token count: (sent + response) / 4
                sent_chars = len(message)
                response_chars = len(markdown or snippet or "")
                tokens_used = (sent_chars + response_chars) // 4
                self._token_count += tokens_used
                
                # Track message in history
                self._message_history.append({
                    "turn": self._turn_count,
                    "timestamp": self._last_interaction_time,
                    "sent_chars": sent_chars,
                    "response_chars": response_chars,
                    "tokens_used": tokens_used,
                })
                
                self._debug(
                    f"Turn: {self._turn_count}, "
                    f"Tokens: {self._token_count}, "
                    f"CTAW: {self.get_ctaw_usage_percent():.1f}%"
                )

            # Add common metadata
            if metadata:
                metadata.update({
                    "ws_source": ws_source,
                    "timestamp": datetime.now(timezone.utc).isoformat().replace("+00:00", "Z"),
                    "turn_count": self._turn_count,
                    "message_count": self._message_count,
                    "token_count": self._token_count,
                    "ctaw_usage_percent": round(self.get_ctaw_usage_percent(), 2),
                    "ctaw_size": self._ctaw_size,
                    "session_duration_s": round(self.get_session_duration_s(), 1),
                })

            return success, snippet, markdown, metadata
            
        finally:
            if remote: await remote.close()
            await pw.stop()

    # =========================
    # Abstract methods (to be implemented by subclasses)
    # =========================

    @abstractmethod
    async def _execute_interaction(
        self,
        page: Page,
        message: str,
        wait_for_response: bool,
        timeout_s: int
    ) -> Tuple[bool, Optional[str], Optional[str], Optional[Dict[str, Any]]]:
        """
        Subclass-specific implementation for the core AI interaction.
        This method is called by the public send_prompt method.
        """
        pass
        
    @abstractmethod
    async def list_messages(self) -> list[Dict[str, Any]]:
        """
        List all messages in the current conversation.
        
        Returns:
            List of message dictionaries with keys:
            - index: int
            - type: 'user' | 'assistant' | 'system'
            - preview: str (first ~60 chars)
            - length: int (character count)
        """
        pass
    
    
    @abstractmethod
    async def extract_message(self, index: int) -> Optional[str]:
        """
        Extract the full content of a specific message.
        
        Args:
            index: Message index (from list_messages)
            
        Returns:
            Full message content or None if not found
        """
        pass
    
    
    # =========================
    # Session state management (implemented in base)
    # =========================
    
    async def get_status(self) -> Dict[str, Any]:
        """
        Get current session status.
        
        Returns:
            Dictionary with connection and session state
        """
        # Ensure CDP info is discovered
        if self._cdp_url is None:
            await self._discover_cdp_url()
        
        ws_url, ws_source = self.get_cdp_info()
        
        return {
            "ai_target": self._config.get("ai_target", "unknown"),
            "connected": ws_url is not None,
            "cdp_source": ws_source,
            "cdp_url": ws_url,
            "last_page_url": self._last_page_url,
            "message_count": self._message_count,
            "turn_count": self._turn_count,
            "token_count": self._token_count,
            "ctaw_size": self._ctaw_size,
            "ctaw_usage_percent": round(self.get_ctaw_usage_percent(), 2),
            "session_duration_s": round(self.get_session_duration_s(), 1),
            "debug_enabled": self._debug_enabled,
        }
    
    def get_turn_count(self) -> int:
        """Get the current turn count for the session."""
        return self._turn_count
    
    def get_message_count(self) -> int:
        """Get the current message count for the session."""
        return self._message_count
    
    def get_token_count(self) -> int:
        """Get the current token count for the session."""
        return self._token_count
    
    def get_ctaw_size(self) -> int:
        """Get the CTAW (context window) size for this AI."""
        return self._ctaw_size
    
    def get_ctaw_usage_percent(self) -> float:
        """
        Get the CTAW usage as a percentage.
        
        Formula: (TokenCount / CTAWSize) * 100
        
        Returns:
            Percentage (0.0 to 100.0+)
        """
        if self._ctaw_size <= 0:
            return 0.0
        return (self._token_count / self._ctaw_size) * 100.0
    
    def get_session_duration_s(self) -> float:
        """Get the session duration in seconds since creation."""
        return time.time() - self._session_start_time
    
    def reset_session_state(self) -> None:
        """
        Reset all session state (call when starting new chat).
        
        This clears turn counter, token counts, and message history.
        """
        self._debug("Resetting session state")
        self._turn_count = 0
        self._message_count = 0
        self._token_count = 0
        self._session_start_time = time.time()
        self._last_interaction_time = None
        self._message_history.clear()

    def reset_turn_count(self) -> None:
        """Reset the session turn count to 0."""
        self._debug("Turn count reset to 0.")
        self._turn_count = 0
        
    def set_debug(self, enabled: bool) -> None:
        """Enable or disable debug output."""
        self._debug_enabled = enabled
    
    
    def get_debug(self) -> bool:
        """Get current debug state."""
        return self._debug_enabled
    
    
    def get_cdp_info(self) -> Tuple[Optional[str], Optional[str]]:
        """
        Get CDP connection information.
        
        Returns:
            Tuple of (ws_url, source) where source is 'env'|'discovered'|'none'
        """
        return self._cdp_url, self._cdp_source
    
    
    def get_cdp_port(self) -> int:
        """Get CDP port from config (default 9223)."""
        try:
            return int(self._config.get("cdp", {}).get("port", 9223))
        except Exception:
            return 9223
            
    def get_base_url(self) -> str:
        """Helper to get base_url from config."""
        return self._config.get("base_url", "")
    
    
    # =========================
    # Protected helpers (available to subclasses)
    # =========================
    
    def _debug(self, msg: str) -> None:
        """Print debug message if debugging is enabled."""
        if self._debug_enabled:
            print(f"[{self.__class__.__name__}] {msg}")
    
    
    # =========================
    # Template methods (can be overridden by subclasses)
    # =========================
    
    async def _discover_cdp_url(self) -> Tuple[Optional[str], str]:
        """
        Discover CDP WebSocket URL.
        
        Default implementation checks:
        1. Environment variable AI_CLI_BRIDGE_CDP_URL
        2. HTTP probe to http://127.0.0.1:<port>/json/version
        
        Subclasses can override for custom discovery logic.
        
        Returns:
            Tuple of (ws_url or None, source: 'env'|'discovered'|'none')
        """
        import os
        from urllib.request import urlopen
        from urllib.error import URLError, HTTPError
        import json
        
        # Check environment variable
        env = (os.environ.get("AI_CLI_BRIDGE_CDP_URL") or "").strip()
        if env.startswith(("ws://", "wss://")) and "/devtools/browser/" in env:
            self._cdp_url = env
            self._cdp_source = "env"
            return env, "env"
        
        # Probe HTTP endpoint
        port = self.get_cdp_port()
        
        url = f"http://127.0.0.1:{port}/json/version"
        try:
            with urlopen(url, timeout=2.0) as resp:
                data = json.loads(resp.read().decode("utf-8"))
                ws = (data.get("webSocketDebuggerUrl") or "").strip()
                if ws.startswith(("ws://", "wss://")) and "/devtools/browser/" in ws:
                    self._cdp_url = ws
                    self._cdp_source = "discovered"
                    return ws, "discovered"
        except (URLError, HTTPError, TimeoutError, ValueError, json.JSONDecodeError):
            pass
        
        self._cdp_url = None
        self._cdp_source = "none"
        return None, "none"
    
    
    async def _pick_page(self, remote, base_url: Optional[str]):
        """
        Pick a page from browser contexts.
        
        Default implementation prefers pages matching base_url, else first page.
        
        Args:
            remote: Playwright browser instance connected via CDP
            base_url: Preferred base URL to match
            
        Returns:
            Page object or None
        """
        try:
            contexts = getattr(remote, "contexts", []) or []
            pages = []
            for ctx in contexts:
                pages.extend(getattr(ctx, "pages", []) or [])
            
            if base_url:
                for p in pages:
                    try:
                        if (p.url or "").startswith(base_url):
                            return p
                    except Exception:
                        continue
            
            return pages[0] if pages else None
        except Exception:
            return None
    
    
    # =========================
    # AI-specific methods (must be implemented by subclasses)
    # =========================
    
    @abstractmethod
    async def _wait_for_response_complete(self, page: Page, timeout_s: int) -> bool:
        """
        Wait for AI response to complete (AI-specific implementation).
        
        Args:
            page: Playwright page object
            timeout_s: Maximum time to wait
            
        Returns:
            True if completion detected, False on timeout
        """
        pass
    
    
    @abstractmethod
    async def _extract_response(
        self,
        page: Page,
        baseline_count: int
    ) -> Tuple[Optional[str], Optional[str]]:
        """
        Extract the last AI response from the page (AI-specific implementation).
        
        Args:
            page: Playwright page object
            baseline_count: Number of responses before sending prompt
            
        Returns:
            Tuple of (snippet, full_markdown) or (None, None)
        """
        pass
    
    
    @abstractmethod
    async def _ensure_chat_ready(self, page: Page) -> bool:
        """
        Ensure the chat interface is ready for input (AI-specific implementation).
        
        Args:
            page: Playwright page object
            
        Returns:
            True if chat is ready, False otherwise
        """
        pass

    @abstractmethod
    async def start_new_session(self, page: Page) -> bool:
        """
        Start a new chat session/conversation (AI-specific implementation).

        Args:
            page: Playwright page object targeting this AI's website.

        Returns:
            True if a new session was started successfully, False otherwise.
        """
        pass


================================================================================
FILE: src/ai_cli_bridge/ai/chatgpt.py
================================================================================

"""ChatGPT-specific AI implementation."""

from typing import Dict, Any

from playwright.async_api import Page

from .web_base import WebAIBase
from .factory import AIFactory


class ChatGPTAI(WebAIBase):
    """ChatGPT-specific implementation using the web AI base."""
    
    # =========================
    # ChatGPT configuration
    # =========================
    
    BASE_URL = "https://chatgpt.com"
    CDP_PORT = 9223
    
    @classmethod
    def get_default_config(cls) -> Dict[str, Any]:
        """Get ChatGPT's default configuration."""
        return {
            "ai_target": "chatgpt",
            "base_url": cls.BASE_URL,
            "cdp": {"port": cls.CDP_PORT},
            "max_context_tokens": 128000  # GPT-4 Turbo context window
        }
    
    # =========================
    # ChatGPT selectors
    # =========================
    
    @property
    def INPUT_BOX(self) -> str:
        return "textarea[name='prompt-textarea']"
    
    @property
    def STOP_BUTTON(self) -> str:
        return "button[data-testid='stop-button']"
    
    @property
    def NEW_CHAT_BUTTON(self) -> str:
        return "a[data-testid='create-new-chat-button']"
    
    @property
    def RESPONSE_CONTAINER(self) -> str:
        return "div[data-message-author-role='assistant']"
    
    @property
    def RESPONSE_CONTENT(self) -> str:
        return "div.markdown.prose"
    
    # =========================
    # ChatGPT-specific overrides
    # =========================
    
    async def _ensure_chat_ready(self, page: Page) -> bool:
        """ChatGPT-specific - skip textarea visibility check."""
        # Navigate to ChatGPT if needed
        if not page.url.startswith(self.get_base_url()):
            try:
                await page.goto(self.get_base_url(), wait_until="domcontentloaded", timeout=10000)
            except Exception:
                return False
        
        # Just check if textarea exists in DOM (even if hidden)
        try:
            textarea = await page.query_selector(self.INPUT_BOX)
            return textarea is not None
        except Exception:
            return False
    
    async def _send_message(self, page: Page, message: str) -> bool:
        """ChatGPT-specific send - handle hidden textarea."""
        try:
            # ChatGPT's textarea is hidden - focus and type
            textarea = await page.query_selector(self.INPUT_BOX)
            if textarea:
                await textarea.focus()
                await page.keyboard.type(message, delay=10)
                await page.keyboard.press("Enter")
                return True
            
            return False
        except Exception:
            return False


# Register ChatGPTAI with factory
AIFactory.register("chatgpt", ChatGPTAI)


================================================================================
FILE: src/ai_cli_bridge/ai/claude.py
================================================================================

"""Claude-specific AI implementation."""

from typing import Dict, Any

from .web_base import WebAIBase
from .factory import AIFactory


class ClaudeAI(WebAIBase):
    """Claude-specific implementation using the web AI base."""
    
    # =========================
    # Claude configuration
    # =========================
    
    BASE_URL = "https://claude.ai"
    CDP_PORT = 9223
    
    @classmethod
    def get_default_config(cls) -> Dict[str, Any]:
        """Get Claude's default configuration."""
        return {
            "ai_target": "claude",
            "base_url": cls.BASE_URL,
            "cdp": {"port": cls.CDP_PORT},
            "max_context_tokens": 200000
        }
    
    # =========================
    # Claude selectors
    # =========================
    
    @property
    def INPUT_BOX(self) -> str:
        return "div[contenteditable='true']"
    
    @property
    def STOP_BUTTON(self) -> str:
        return "button[aria-label='Stop response']"
    
    @property
    def NEW_CHAT_BUTTON(self) -> str:
        return "button[aria-label*='New chat']"
    
    @property
    def RESPONSE_CONTAINER(self) -> str:
        return ".font-claude-response"
    
    @property
    def RESPONSE_CONTENT(self) -> str:
        return ".standard-markdown"


# Register ClaudeAI with factory
AIFactory.register("claude", ClaudeAI)


================================================================================
FILE: src/ai_cli_bridge/ai/factory.py
================================================================================

"""Factory for creating AI instances."""

from typing import Dict, Any
from .base import BaseAI


class AIFactory:
    """
    Factory class for creating AI instances.
    
    Manages registration and instantiation of AI implementations.
    """
    
    _registry: Dict[str, type[BaseAI]] = {}
    
    @classmethod
    def register(cls, ai_name: str, ai_class: type[BaseAI]) -> None:
        """
        Register an AI implementation.
        
        Args:
            ai_name: Lowercase AI identifier (e.g., 'claude', 'chatgpt')
            ai_class: AI class that inherits from BaseAI
        """
        normalized_name = ai_name.lower().strip()
        cls._registry[normalized_name] = ai_class
    
    
    @classmethod
    def get_class(cls, ai_name: str) -> type[BaseAI]:
        """
        Get the AI class without instantiating it.
        
        Args:
            ai_name: AI identifier (e.g., 'claude', 'chatgpt')
            
        Returns:
            The AI class (not an instance)
            
        Raises:
            ValueError: If AI name is not registered
        """
        normalized_name = ai_name.lower().strip()
        
        if normalized_name not in cls._registry:
            available = ", ".join(cls._registry.keys())
            raise ValueError(
                f"Unknown AI: '{ai_name}'. "
                f"Available: {available}"
            )
        
        return cls._registry[normalized_name]
    
    
    @classmethod
    def create(cls, ai_name: str, config: Dict[str, Any]) -> BaseAI:
        """
        Create an AI instance.
        
        Args:
            ai_name: AI identifier (e.g., 'claude', 'chatgpt')
            config: Configuration dictionary
            
        Returns:
            Instance of the appropriate AI class
            
        Raises:
            ValueError: If AI name is not registered
        """
        ai_class = cls.get_class(ai_name)
        return ai_class(config)
    
    
    @classmethod
    def list_available(cls) -> list[str]:
        """
        List all registered AI names.
        
        Returns:
            List of lowercase AI identifiers
        """
        return sorted(cls._registry.keys())
    
    
    @classmethod
    def is_registered(cls, ai_name: str) -> bool:
        """
        Check if an AI is registered.
        
        Args:
            ai_name: AI identifier
            
        Returns:
            True if registered, False otherwise
        """
        return ai_name.lower().strip() in cls._registry
    
    
    @classmethod
    def import_all_ais(cls) -> None:
        """
        Import all AI modules to trigger their registration.
        
        This must be called before using list_available() or create()
        to ensure all AI implementations are loaded.
        """
        # Import all AI implementations
        # The import statements will trigger the AIFactory.register() calls
        # at the bottom of each AI module
        try:
            from . import claude
        except ImportError as e:
            print(f"Warning: Could not import claude: {e}")
        
        try:
            from . import gemini
        except ImportError as e:
            print(f"Warning: Could not import gemini: {e}")
        
        #try:
            from . import chatgpt
        except ImportError as e:
            print(f"Warning: Could not import chatgpt: {e}")


================================================================================
FILE: src/ai_cli_bridge/ai/gemini.py
================================================================================

"""Gemini-specific AI implementation."""

from typing import Dict, Any

from .web_base import WebAIBase
from .factory import AIFactory


class GeminiAI(WebAIBase):
    """Gemini-specific implementation using the web AI base."""
    
    # =========================
    # Gemini configuration
    # =========================
    
    BASE_URL = "https://gemini.google.com"
    CDP_PORT = 9223
    
    @classmethod
    def get_default_config(cls) -> Dict[str, Any]:
        """Get Gemini's default configuration."""
        return {
            "ai_target": "gemini",
            "base_url": cls.BASE_URL,
            "cdp": {"port": cls.CDP_PORT},
            "max_context_tokens": 2000000
        }
    
    # =========================
    # Gemini selectors
    # =========================
    
    @property
    def INPUT_BOX(self) -> str:
        return "div.ql-editor[aria-label*='prompt']"
    
    @property
    def STOP_BUTTON(self) -> str:
        return "button[aria-label='Stop response']"
    
    @property
    def NEW_CHAT_BUTTON(self) -> str:
        return "a.new-chat-button"
    
    @property
    def RESPONSE_CONTAINER(self) -> str:
        return "div.response-container-content"
    
    @property
    def RESPONSE_CONTENT(self) -> str:
        return "div.markdown"


# Register GeminiAI with factory
AIFactory.register("gemini", GeminiAI)


================================================================================
FILE: src/ai_cli_bridge/ai/__init__.py
================================================================================

"""AI abstraction layer for browser automation."""

from .base import BaseAI
from .factory import AIFactory

# Import AI implementations to trigger registration
from .claude import ClaudeAI
from .chatgpt import ChatGPTAI
from .gemini import GeminiAI

__all__ = ["BaseAI", "AIFactory", "ClaudeAI", "ChatGPTAI", "GeminiAI"]


================================================================================
FILE: src/ai_cli_bridge/ai/web_base.py
================================================================================

"""Base class for web-based AIs using the stop-button pattern."""

import asyncio
import time
from abc import abstractmethod
from typing import Optional, Tuple, Dict, Any

from playwright.async_api import Page, TimeoutError as PWTimeout
from .base import BaseAI

try:
    import markdownify
except ImportError:
    markdownify = None


class WebAIBase(BaseAI):
    """
    Base class for web-based AI interfaces that follow the stop-button pattern.
    
    This covers AIs like Claude and Gemini that:
    - Use contenteditable input boxes
    - Show a "Stop" button during response generation
    - Hide the button when complete
    - Extract responses from markdown containers
    
    Subclasses must define selectors and AI-specific logic.
    """
    
    # =========================
    # Common timing constants
    # =========================
    
    RESPONSE_WAIT_S = 10.0
    COMPLETION_CHECK_INTERVAL_S = 0.2
    SNIPPET_LENGTH = 280
    SNIPPET_TRIM_WINDOW = 40
    
    # =========================
    # Abstract selectors (must be defined by subclass)
    # =========================
    
    @property
    @abstractmethod
    def INPUT_BOX(self) -> str:
        """Selector for the message input box."""
        pass
    
    @property
    @abstractmethod
    def STOP_BUTTON(self) -> str:
        """Selector for the stop/cancel button during generation."""
        pass
    
    @property
    @abstractmethod
    def NEW_CHAT_BUTTON(self) -> str:
        """Selector for the new chat button."""
        pass
    
    @property
    @abstractmethod
    def RESPONSE_CONTAINER(self) -> str:
        """Selector for the response container element."""
        pass
    
    @property
    @abstractmethod
    def RESPONSE_CONTENT(self) -> str:
        """Selector for the actual response content within container."""
        pass
    
    # =========================
    # Shared implementation
    # =========================
    
    async def _execute_interaction(
        self,
        page: Page,
        message: str,
        wait_for_response: bool,
        timeout_s: int
    ) -> Tuple[bool, Optional[str], Optional[str], Optional[Dict[str, Any]]]:
        """Standard web AI interaction flow."""
        
        if not await self._ensure_chat_ready(page):
            return False, None, None, {"error": "chat_not_ready"}
        
        baseline_count = await self._get_response_count(page)
        
        if not await self._send_message(page, message):
            return False, None, None, {"error": "send_failed"}
        
        snippet, markdown, elapsed_ms = None, None, None
        
        if wait_for_response:
            t0 = time.time()
            
            completed = await self._wait_for_response_complete(page, timeout_s)
            
            if completed:
                snippet, markdown = await self._extract_response(page, baseline_count)
            
            elapsed_ms = int((time.time() - t0) * 1000)
        
        metadata = {
            "page_url": page.url,
            "elapsed_ms": elapsed_ms,
            "waited": wait_for_response,
        }
        
        return True, snippet, markdown, metadata
    
    async def start_new_session(self, page: Page) -> bool:
        """Start a new chat session (standard implementation)."""
        try:
            button = page.locator(self.NEW_CHAT_BUTTON).first
            await button.wait_for(state="visible", timeout=5000)
            await button.click()
            
            await page.wait_for_selector(self.INPUT_BOX, state="visible", timeout=5000)
            return True
        except Exception:
            return False
    
    async def _ensure_chat_ready(self, page: Page) -> bool:
        """Ensure chat interface is ready for input."""
        # Navigate if needed
        if not page.url.startswith(self.get_base_url()):
            try:
                await page.goto(
                    self.get_base_url(),
                    wait_until="domcontentloaded",
                    timeout=10000
                )
            except Exception:
                return False
        
        # Wait for input box
        try:
            await page.wait_for_selector(self.INPUT_BOX, state="visible", timeout=5000)
            return True
        except PWTimeout:
            return False
    
    async def _send_message(self, page: Page, message: str) -> bool:
        """Send message to the AI."""
        try:
            await page.fill(self.INPUT_BOX, message, timeout=5000)
            await page.keyboard.press("Enter")
            return True
        except Exception:
            return False
    
    async def _wait_for_response_complete(self, page: Page, timeout_s: int) -> bool:
        """Wait for response to complete using stop-button pattern."""
        try:
            # Wait for stop button to appear
            await page.wait_for_selector(self.STOP_BUTTON, state="visible", timeout=10000)
            
            # Poll until it disappears
            deadline = time.time() + timeout_s
            while time.time() < deadline:
                if await page.locator(self.STOP_BUTTON).count() == 0:
                    return True
                await asyncio.sleep(self.COMPLETION_CHECK_INTERVAL_S)
            
            return False
        
        except PWTimeout:
            # Stop button never appeared (instant response)
            return True
        except Exception:
            return True
    
    async def _extract_response(
        self,
        page: Page,
        baseline_count: int
    ) -> Tuple[Optional[str], Optional[str]]:
        """Extract the last response from the page."""
        content_sel = f"{self.RESPONSE_CONTAINER}:has({self.RESPONSE_CONTENT})"
        
        try:
            # Wait for new response
            deadline = time.time() + self.RESPONSE_WAIT_S
            while time.time() < deadline:
                if await page.locator(content_sel).count() > baseline_count:
                    break
                await asyncio.sleep(self.COMPLETION_CHECK_INTERVAL_S)
            
            # Get last response content
            last_response_content = page.locator(self.RESPONSE_CONTENT).last
            if await last_response_content.count() == 0:
                return None, None
            
            html = await last_response_content.inner_html()
            if not html:
                return None, None
            
            # Convert to markdown
            if markdownify:
                markdown_text = markdownify.markdownify(html, heading_style="ATX").strip()
            else:
                markdown_text = await last_response_content.inner_text()
            
            snippet = self._create_snippet(markdown_text)
            
            return snippet, markdown_text
        
        except Exception:
            return None, None
    
    async def _get_response_count(self, page: Page) -> int:
        """Get current count of response containers."""
        content_sel = f"{self.RESPONSE_CONTAINER}:has({self.RESPONSE_CONTENT})"
        try:
            return await page.locator(content_sel).count()
        except Exception:
            return 0
    
    def _create_snippet(self, text: str) -> str:
        """Create smart-trimmed snippet from text."""
        if not text:
            return ""
        
        if len(text) <= self.SNIPPET_LENGTH:
            return text
        
        cut = text[:self.SNIPPET_LENGTH]
        last_break = max(
            cut.rfind("\n"), cut.rfind(" "), cut.rfind("."),
            cut.rfind("!"), cut.rfind("?")
        )
        
        if last_break >= self.SNIPPET_LENGTH - self.SNIPPET_TRIM_WINDOW:
            return cut[:last_break].rstrip() + " …"
        
        return cut + " …"
    
    # =========================
    # Abstract stubs (not implemented for web AIs yet)
    # =========================
    
    async def list_messages(self) -> list[Dict[str, Any]]:
        raise NotImplementedError(f"list_messages not yet implemented for {self.__class__.__name__}")
    
    async def extract_message(self, index: int) -> Optional[str]:
        raise NotImplementedError(f"extract_message not yet implemented for {self.__class__.__name__}")


================================================================================
FILE: src/ai_cli_bridge/browser_manager.py
================================================================================

from __future__ import annotations

from contextlib import asynccontextmanager
from playwright.async_api import async_playwright, Page, BrowserContext
from .errors import E, die
from .display import has_display

import asyncio
import sys
import os
import json
import time
from urllib.request import urlopen
from urllib.error import URLError


# ---------------------------------------------------------------------------
# Configuration & Detection
# ---------------------------------------------------------------------------

def _get_cdp_url() -> str | None:
    """
    Return the CDP URL (ws://127.0.0.1:PORT/devtools/browser/<id>) if the user
    has exported AI_CLI_BRIDGE_CDP_URL. When present, we attach to an *external*
    headed browser instead of launching our own.
    """
    return os.environ.get("AI_CLI_BRIDGE_CDP_URL")


async def _ensure_cdp_browser(cfg) -> str | None:
    """
    Best-effort autostart for a CDP-enabled headed browser (Flatpak Ungoogled Chromium).
    Triggered only if:
      - AI_CLI_BRIDGE_CDP_URL is not set AND
      - config["cdp"]["enable_autostart"] is true

    Launches the browser with:
      --remote-debugging-address=127.0.0.1
      --remote-debugging-port=<port>
      --user-data-dir=<profile>
      --no-first-run --new-window
      <startup_urls...>

    Then polls http://127.0.0.1:<port>/json/version for webSocketDebuggerUrl.
    If obtained, sets AI_CLI_BRIDGE_CDP_URL and returns the ws URL.

    Returns None on failure without aborting (the caller may still proceed in non-CDP mode).
    """
    cdp = (cfg or {}).get("cdp") or {}
    if not cdp.get("enable_autostart"):
        return None

    port = int(cdp.get("port", 9222))
    wait_seconds = int(cdp.get("wait_seconds", 12))
    flatpak_id = cdp.get("flatpak_id", "io.github.ungoogled_software.ungoogled_chromium")
    user_data_dir = os.path.expanduser(cdp.get("user_data_dir", "~/.ai_cli_bridge/data/profiles/claude_cdp"))
    startup_urls = cdp.get("startup_urls") or ["https://claude.ai/chat"]

    cmd = [
        "flatpak", "run", flatpak_id,
        "--remote-debugging-address=127.0.0.1",
        f"--remote-debugging-port={port}",
        f"--user-data-dir={user_data_dir}",
        "--no-first-run", "--new-window",
        *startup_urls,
    ]

    try:
        # Fire-and-forget; do not await completion of the GUI app
        await asyncio.create_subprocess_exec(*cmd)
    except Exception as e:
        print(f"[AI-CLI-BRIDGE] CDP autostart failed to launch: {e}", file=sys.stderr)
        return None

    ws_url = None
    deadline = time.time() + wait_seconds
    version_url = f"http://127.0.0.1:{port}/json/version"
    while time.time() < deadline and not ws_url:
        try:
            with urlopen(version_url, timeout=1.0) as r:
                data = json.load(r)
                ws_url = data.get("webSocketDebuggerUrl")
                if ws_url:
                    break
        except URLError:
            pass
        except Exception:
            pass
        await asyncio.sleep(0.25)

    if ws_url:
        os.environ["AI_CLI_BRIDGE_CDP_URL"] = ws_url
        print(f"[AI-CLI-BRIDGE] CDP ready: {ws_url}", file=sys.stderr)
        return ws_url

    print("[AI-CLI-BRIDGE] CDP autostart did not become ready in time.", file=sys.stderr)
    return None


# ---------------------------------------------------------------------------
# Challenge detection & readiness checks
# ---------------------------------------------------------------------------

CHALLENGE_LOCATORS = [
    # Generic
    "iframe[title*='challenge']",
    "iframe[src*='challenge']",
    "[data-testid*='challenge']",
    "text=/verify you are human/i",
    "text=/are you a human/i",
    "div:has-text('Verify you are human')",

    # Cloudflare Turnstile
    "iframe[src*='challenges.cloudflare.com']",
    ".cf-challenge",
    ".cf-turnstile",
    "div[aria-label*='challenge']",

    # Arkose / FunCaptcha
    "iframe[src*='funcaptcha.com']",
    "iframe[src*='arkoselabs.com']",
]


async def _any_visible(page: Page, selectors: list[str]) -> str | None:
    """Return the first selector that is currently visible, else None."""
    for sel in selectors:
        if not sel:
            continue
        try:
            if await page.locator(sel).first.is_visible():
                return sel
        except Exception:
            pass
    return None


async def _check_auth_readiness(page: Page, cfg, timeout: int = 10) -> tuple[bool, str]:
    """
    Verify auth readiness per spec Section 5:
      1) input_box present & enabled
      2) login_form absent
      3) error_indicator absent
    """
    selectors = cfg.get("selectors", {}) or {}
    input_box = selectors.get("input_box")
    login_form = selectors.get("login_form")
    error_indicator = selectors.get("error_indicator")

    try:
        # 1) input_box present & enabled
        if input_box:
            locator = page.locator(input_box).first
            await locator.wait_for(state="visible", timeout=timeout * 1000)
            if not await locator.is_enabled():
                return False, "Input box not enabled"

        # 2) login_form absent
        if login_form and await _any_visible(page, [login_form]):
            return False, "Login form still visible"

        # 3) error_indicator absent
        if error_indicator and await _any_visible(page, [error_indicator]):
            return False, "Error indicator present"

        return True, "Auth ready"

    except Exception as e:
        return False, f"Auth check failed: {e}"


async def wait_for_challenge_clear(page: Page, timeout: int = 120) -> bool:
    """
    Detect a human-verification challenge and wait until it disappears.
    Returns True if a challenge was detected and later cleared; False if none found.
    Raises E.E002 if it doesn't clear within `timeout`.
    """
    sel = await _any_visible(page, CHALLENGE_LOCATORS)
    if not sel:
        return False

    print(
        f"[AI-CLI-BRIDGE] Human verification detected ({sel}) — waiting up to {timeout}s...",
        file=sys.stderr,
    )
    try:
        await page.wait_for_selector(sel, state="hidden", timeout=timeout * 1000)
        print("[AI-CLI-BRIDGE] Challenge cleared.", file=sys.stderr)
        return True
    except asyncio.TimeoutError:
        die(E.E002, f"Challenge not cleared after {timeout}s. Please complete verification and retry.")


# ---------------------------------------------------------------------------
# Fingerprint softening (heads-only, gentle)
# ---------------------------------------------------------------------------

SOFTEN_ARGS = [
    "--disable-blink-features=AutomationControlled",
    "--disable-infobars",
    "--password-store=basic",
    "--use-mock-keychain",
]

REALISTIC_UA = (
    "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 "
    "(KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36"
)

STEALTH_INIT_JS = """
// 1) navigator.webdriver → undefined
Object.defineProperty(navigator, 'webdriver', { get: () => undefined });

// 2) plugins & languages look normal
try {
  Object.defineProperty(navigator, 'languages', { get: () => ['en-US','en'] });
  Object.defineProperty(navigator, 'plugins',   { get: () => [1,2,3] });
} catch (e) {}

// 3) Permissions.query spoof (common probe)
const _query = (navigator.permissions && navigator.permissions.query)
  ? navigator.permissions.query.bind(navigator.permissions)
  : null;
if (_query) {
  navigator.permissions.query = (params) => {
    if (params && params.name === 'notifications') {
      return Promise.resolve({ state: Notification.permission });
    }
    return _query(params);
  };
}

// 4) WebGL vendor/renderer echo (plausible AMD on Linux)
(function() {
  const VENDOR  = "AMD";
  const RENDERER = "AMD Radeon 680M (RADV NAVI3X)";

  function patch(getParameter) {
    return function(pname) {
      const gl = this;
      try {
        const dbg = gl.getExtension && (gl.getExtension('WEBGL_debug_renderer_info')
                 || gl.getExtension('MOZ_WEBGL_debug_renderer_info')
                 || gl.getExtension('WEBKIT_WEBGL_debug_renderer_info'));
        if (dbg) {
          const UNMASKED_VENDOR = dbg.UNMASKED_VENDOR_WEBGL;
          const UNMASKED_RENDERER = dbg.UNMASKED_RENDERER_WEBGL;
          if (pname === UNMASKED_VENDOR)   return VENDOR;
          if (pname === UNMASKED_RENDERER) return RENDERER;
        }
      } catch (e) {}
      return getParameter.apply(this, arguments);
    };
  }

  try {
    const p1 = (typeof WebGLRenderingContext !== 'undefined') && WebGLRenderingContext.prototype;
    if (p1 && p1.getParameter) {
      const orig = p1.getParameter;
      Object.defineProperty(p1, 'getParameter', { value: patch(orig) });
    }
  } catch (_) {}

  try {
    const p2 = (typeof WebGL2RenderingContext !== 'undefined') && WebGL2RenderingContext.prototype;
    if (p2 && p2.getParameter) {
      const orig = p2.getParameter;
      Object.defineProperty(p2, 'getParameter', { value: patch(orig) });
    }
  } catch (_) {}
})();
"""


# ---------------------------------------------------------------------------
# Main: launch/attach browser and ensure readiness
# ---------------------------------------------------------------------------

@asynccontextmanager
async def launch_browser(cfg):
    """
    Launch (or attach to) a headed Chromium context per V1.3.1 spec.

    Modes:
      - CDP mode (preferred): if AI_CLI_BRIDGE_CDP_URL is present OR config.cdp.enable_autostart is true,
        attach to user's *external* browser (Flatpak Ungoogled Chromium).
      - Fallback mode: launch Playwright's persistent context (headed).

    Navigation policy:
      - Prefer an existing Claude tab (CDP mode).
      - Only navigate if not already on the desired origin/path.
      - Perform human-challenge wait only if a challenge is actually present.
      - Verify auth readiness (input present & enabled, no login form, no error indicator).
    """
    if not has_display():
        die(E.E001, "No display available. AI-CLI-Bridge cannot run headless.")

    playwright = None
    browser: BrowserContext | None = None

    try:
        playwright = await async_playwright().start()

        # CDP autostart (if env not set) — frictionless startup
        cdp_url = _get_cdp_url() or await _ensure_cdp_browser(cfg)

        if cdp_url:
            # ----- External Browser (CDP) Mode: attach to headed browser -----
            try:
                remote = await playwright.chromium.connect_over_cdp(cdp_url)
            except Exception as e:
                await playwright.stop()
                die(E.E002, f"CDP connect failed: {e}. Ensure remote debugging is enabled.")
            # Adopt an existing page or create a new one
            try:
                contexts = getattr(remote, "contexts", []) or []
                pages = contexts[0].pages if contexts else []
                page: Page = pages[0] if pages else await contexts[0].new_page()
            except Exception:
                page = await remote.new_page()
            browser = remote  # maintain variable naming consistency

        else:
            # ----- Default Mode: Playwright-bundled Chromium (persistent, headed) -----
            browser = await playwright.chromium.launch_persistent_context(
                user_data_dir=str(cfg["_profile_dir"]),
                headless=False,                 # headed-only per spec
                args=SOFTEN_ARGS,               # reduce common automation markers
                user_agent=REALISTIC_UA,        # align navigator.userAgent
                locale="en-US",
            )
            # Inject stealth fixes for all pages in this persistent context
            await browser.add_init_script(STEALTH_INIT_JS)
            # Conservative, realistic UA + CH (Linux + Chromium 129)
            await browser.set_extra_http_headers({
                "User-Agent": REALISTIC_UA,
                "sec-ch-ua": "\"Chromium\";v=\"129\", \"Not=A?Brand\";v=\"24\"",
                "sec-ch-ua-mobile": "?0",
                "sec-ch-ua-platform": "\"Linux\"",
            })
            page = browser.pages[0] if browser.pages else await browser.new_page()

        # ------------------------
        # Tab selection / navigation
        # ------------------------
        target_url = cfg.get("_conversation_url") or cfg.get("base_url", "https://claude.ai")

        # In CDP mode, prefer an already-open Claude tab if present
        try:
            from urllib.parse import urlparse
            def _host(u: str):
                try:
                    pu = urlparse(u or "")
                    return (pu.scheme or "", pu.hostname or "", pu.port or -1)
                except Exception:
                    return ("", "", -1)

            if _get_cdp_url():
                pages = []
                try:
                    contexts = getattr(browser, "contexts", []) or []
                    for ctx in contexts:
                        pages.extend(getattr(ctx, "pages", []) or [])
                except Exception:
                    pass
                for p in pages:
                    u = getattr(p, "url", "") or ""
                    sch, host, port = _host(u)
                    if sch == "https" and host == "claude.ai":
                        page = p
                        break
        except Exception:
            pass

        # Only navigate if we're not already on the desired origin/path
        def _same_origin(u: str, v: str) -> bool:
            try:
                from urllib.parse import urlparse
                pu, pv = urlparse(u), urlparse(v)
                return (pu.scheme, pu.hostname, pu.port or -1) == (pv.scheme, pv.hostname, pv.port or -1)
            except Exception:
                return False

        try:
            cur = page.url
        except Exception:
            cur = ""

        should_navigate = True
        if cur and target_url:
            # If on same origin and already a Claude route, avoid a reload (reduces CAPTCHA risk)
            if _same_origin(cur, target_url) and cur.startswith("https://claude.ai/"):
                should_navigate = False

        if should_navigate:
            await page.goto(target_url, timeout=cfg["timeouts"]["page_load"] * 1000)

        # Gentle motion/scroll to add human-like entropy (no clicks/typing)
        try:
            await page.wait_for_timeout(800)
            vw = await page.evaluate("() => window.innerWidth")
            vh = await page.evaluate("() => window.innerHeight")
            await page.mouse.move(int(vw * 0.3), int(vh * 0.5), steps=8)
            await page.wait_for_timeout(140)
            await page.mouse.move(int(vw * 0.6), int(vh * 0.3), steps=10)
            await page.wait_for_timeout(200)
            await page.mouse.wheel(delta_y=200)
        except Exception:
            pass

        # Human-verification challenge handling (only if present)
        challenge_timeout = cfg["timeouts"].get("response_wait", 120)
        await wait_for_challenge_clear(page, timeout=challenge_timeout)

        # Auth readiness (per spec §5)
        ready, message = await _check_auth_readiness(page, cfg, timeout=cfg["timeouts"]["page_load"])
        if not ready:
            # Soft retry once if a challenge element is still present
            try:
                if await _any_visible(page, CHALLENGE_LOCATORS):
                    await page.wait_for_timeout(15000)
                    ready, message = await _check_auth_readiness(page, cfg, timeout=cfg["timeouts"]["page_load"])
            except Exception:
                pass

        if not ready:
            die(E.E002, f"Auth not ready: {message}. Open the page and complete login, then retry.")

    except Exception as e:
        # Teardown on error
        if browser:
            try:
                await browser.close()
            except Exception:
                pass
        if playwright:
            try:
                await playwright.stop()
            except Exception:
                pass
        if isinstance(e, SystemExit):
            raise
        die(E.E002, f"Browser launch failed: {e}")

    try:
        # Yield the ready page to callers (open/send/etc.)
        yield page
    finally:
        # Graceful shutdown:
        # - CDP mode: DO NOT close the external browser; leave tabs intact.
        # - Persistent mode: close our browser context.
        try:
            if _get_cdp_url():
                # leave external browser running; nothing to do
                pass
            else:
                await browser.close()
        except Exception:
            pass
        try:
            await playwright.stop()
        except Exception:
            pass



================================================================================
FILE: src/ai_cli_bridge/cli.py
================================================================================

# ai_cli_bridge/cli.py

from __future__ import annotations
import typer

# Import run() directly from each module (harmonized style)
from .commands.open_cmd import run as open_run
from .commands.doctor_cmd import run as doctor_run
from .commands.init_cmd import run as init_run
from .commands.init_cdp_cmd import run as init_cdp_run
from .commands.status_cmd import run as status_run
from .commands.send_cmd import run as send_run

# Import daemon command group
from .daemon import daemon_cmd

app = typer.Typer(
    add_completion=False,
    help="ai-cli-bridge — Drive logged-in AI web UIs via CDP (Playwright).",
    no_args_is_help=True,
)

# Add daemon subcommand group
app.add_typer(daemon_cmd.app, name="daemon")

@app.command("init")
def init(
    ai_name: str = typer.Argument(..., help="Target AI profile to initialize (non-CDP)."),
):
    """
    Initialize target AI profile (non-CDP).
    """
    raise typer.Exit(init_run(ai_name))


@app.command("init-cdp")
def init_cdp(
    ai_name: str = typer.Argument(..., help="Target AI (e.g., 'claude'). Launch Playwright Chromium in CDP mode."),
):
    """
    Launch Playwright Chromium with remote debugging and a persistent user data dir.
    Prints the DevTools ws URL.
    """
    raise typer.Exit(init_cdp_run(ai_name))


@app.command("open")
def open_cmd(
    ai_name: str = typer.Argument(..., help="Target AI profile (e.g., 'claude')."),
    conversation: str | None = typer.Option(
        None,
        "--conversation",
        help="Optional conversation URL to open/attach.",
    ),
    force: bool = typer.Option(
        False,
        "--force",
        help="Force navigation even if already on the same origin.",
    ),
):
    """
    Attach to the running CDP Chromium and open/attach to a target conversation.
    Respects 'no reload if already on origin' logic.
    """
    raise typer.Exit(open_run(ai_name, conversation, force))


@app.command("send")
def send(
    ai_name: str = typer.Argument(..., help="Target AI profile (e.g., 'claude')."),
    message: str = typer.Argument(..., help="Text to send to the current conversation."),
    wait: bool = typer.Option(
        True,
        "--wait/--no-wait",
        help="Wait for assistant response and return a snippet (default: --wait).",
    ),
    timeout: int = typer.Option(
        120,
        "--timeout",
        help="Overall wait timeout in seconds (default 120; if unchanged, config.response_wait applies).",
        min=1,
    ),
    json: bool = typer.Option(
        False,
        "--json",
        help="Emit a JSON envelope (includes 'snippet' and 'markdown' when available).",
    ),
    debug: bool = typer.Option(
        False,
        "--debug",
        help="Enable debug output.",
    ),
):
    """
    Send a message to the current conversation.
    """
    raise typer.Exit(send_run(ai_name, message, wait, timeout, json, debug))

@app.command("doctor")
def doctor():
    """
    Basic environment/system checks.
    """
    raise typer.Exit(doctor_run())


@app.command("status")
def status(
    ai_name: str = typer.Argument(..., help="Target AI profile name (e.g., 'claude')."),
    json: bool = typer.Option(False, "--json", help="Emit a JSON envelope."),
):
    """Report CDP attach, current page URL, and selector sanity for the target."""
    raise typer.Exit(status_run(ai_name, json))


@app.command("version")
def version():
    """
    Print ai-cli-bridge version.
    """
    typer.echo("ai-cli-bridge 2.0.0")


def main():
    app()


if __name__ == "__main__":
    main()


================================================================================
FILE: src/ai_cli_bridge/commands/doctor_cmd.py
================================================================================

from ..config import ensure_dirs
from ..display import has_display, mode
def run(startup:bool, as_json:bool):
    ensure_dirs()
    if startup:
        print(f"✓ Display: {'Available' if has_display() else 'Unavailable'} ({mode()})")
        try:
            import playwright; playwright  # noqa
            print("✓ Playwright: installed")
        except Exception as e:
            print(f"✗ Playwright: NOT installed ({e})")
        return 0
    else:
        print("✓ Doctor (standard): full live checks come after open in the next step")
        return 0


================================================================================
FILE: src/ai_cli_bridge/commands/init_cdp_cmd.py
================================================================================

# ai_cli_bridge/commands/init_cdp_cmd.py

import json
import os
import socket
import subprocess
import time
from pathlib import Path
from typing import Any, Dict

from ..config import load
from ..errors import E, die


def _is_port_open(port: int) -> bool:
    try:
        with socket.create_connection(("127.0.0.1", port), timeout=0.5):
            return True
    except OSError:
        return False


def _ensure_dir(p: str):
    d = Path(p)
    d.mkdir(parents=True, exist_ok=True)
    # lock down perms per spec
    os.chmod(d, 0o700)


def _launch_playwright(cdp_cfg: Dict[str, Any]) -> subprocess.Popen:
    """
    Launch Playwright-bundled Chromium with:
      --remote-debugging-port
      --user-data-dir
      startup URLs
    """
    port = int(cdp_cfg.get("port", 9223))
    user_data_dir = cdp_cfg.get("user_data_dir")
    if not user_data_dir:
        die(E.E003, "cdp.user_data_dir is required for launcher=playwright")

    _ensure_dir(user_data_dir)

    # Locate the Playwright Chromium executable
    py = (
        "from playwright.sync_api import sync_playwright; "
        "p=sync_playwright().start(); "
        "print(p.chromium.executable_path); "
        "p.stop()"
    )
    try:
        exe = subprocess.check_output(["python", "-c", py], text=True).strip()
    except Exception as e:
        die(E.E003, f"Unable to locate Playwright Chromium: {e}")

    urls = list(cdp_cfg.get("startup_urls") or [])
    args = [
        exe,
        f"--remote-debugging-port={port}",
        f"--user-data-dir={user_data_dir}",
        "--no-first-run",
        "--new-window",
    ] + urls

    # Launch detached so CLI can return while browser lives
    return subprocess.Popen(args, stdout=subprocess.PIPE, stderr=subprocess.PIPE)


def _launch_flatpak(cdp_cfg: Dict[str, Any]) -> subprocess.Popen:
    """
    Launch Ungoogled Chromium Flatpak with remote debugging.
    """
    port = int(cdp_cfg.get("port", 9222))
    user_data_dir = cdp_cfg.get("user_data_dir")
    flatpak_id = cdp_cfg.get("flatpak_id", "io.github.ungoogled_software.ungoogled_chromium")

    if not user_data_dir:
        die(E.E003, "cdp.user_data_dir is required for launcher=flatpak")

    _ensure_dir(user_data_dir)

    urls = list(cdp_cfg.get("startup_urls") or [])
    base = [
        "flatpak", "run", flatpak_id,
        f"--remote-debugging-port={port}",
        f"--user-data-dir={user_data_dir}",
        "--no-first-run",
        "--new-window",
    ]
    args = base + urls
    return subprocess.Popen(args, stdout=subprocess.PIPE, stderr=subprocess.PIPE)


def _wait_for_ws(port: int, wait_seconds: int) -> str | None:
    """
    Poll /json/version until webSocketDebuggerUrl is present, or timeout.
    """
    import urllib.request
    deadline = time.time() + max(1, wait_seconds)
    while time.time() < deadline:
        try:
            with urllib.request.urlopen(f"http://127.0.0.1:{port}/json/version", timeout=1.5) as r:
                meta = json.loads(r.read().decode("utf-8", "ignore"))
            ws = meta.get("webSocketDebuggerUrl") or meta.get("websocketDebuggerUrl")
            if ws and ws != "null":
                return ws
        except Exception:
            pass
        time.sleep(0.4)
    return None


def run(ai_name: str) -> int:
    """
    Launch a CDP-enabled browser for the given AI config and print a ws:// URL.
    Returns exit code: 0 on success, 1 on failure.
    """
    cfg = load(ai_name)
    cdp = cfg.get("cdp") or {}
    if not cdp:
        die(E.E003, f"No 'cdp' block found in config for '{ai_name}'")

    launcher = (cdp.get("launcher") or "flatpak").strip().lower()
    port = int(cdp.get("port") or (9223 if launcher == "playwright" else 9222))
    wait_seconds = int(cdp.get("wait_seconds") or 10)

    # If something is already listening, don't double-launch; just try to read the ws endpoint.
    proc = None
    try:
        if not _is_port_open(port):
            print("Launching CDP browser...")
            if launcher == "playwright":
                proc = _launch_playwright(cdp)
            elif launcher == "flatpak":
                proc = _launch_flatpak(cdp)
            else:
                die(E.E003, f"Unknown cdp.launcher '{launcher}'. Expected 'playwright' or 'flatpak'.")

        ws = _wait_for_ws(port, wait_seconds)
        if not ws:
            if proc and proc.poll() is not None:
                # Process died early; show a hint
                try:
                    _, err = proc.communicate(timeout=0.5)
                    err_txt = err.decode("utf-8", "ignore")
                except Exception:
                    err_txt = "(no stderr)"
                die(E.E002, f"DevTools endpoint not available. Browser exited early.\n{err_txt}")
            die(E.E002, "DevTools endpoint not available. Is the browser blocked by pop-ups or policy?")

        print(f"CDP ready: {ws}")
        print("Tip: export this in your shell if you want it available to subsequent commands:")
        print(f'export AI_CLI_BRIDGE_CDP_URL="{ws}"')
        return 0
    finally:
        # Do NOT kill the browser; leave it running for the session.
        pass



================================================================================
FILE: src/ai_cli_bridge/commands/init_cmd.py
================================================================================

"""Init command per spec Section 8.7."""
import sys
from pathlib import Path
from ..config import load, ensure_dirs
from ..errors import E, die


def run(ai_name: str):
    """
    Initialize AI target configuration.
    
    Per spec Section 8.7:
    - Normalize AI name
    - Create skeleton config & profile directory (0700)
    - Idempotent
    """
    ensure_dirs()
    
    # Normalize AI name: lowercase, [a-z0-9_-], collapse underscores, max 32
    ai_name = ai_name.lower().strip()
    ai_name = ''.join(c if c.isalnum() or c in '_-' else '_' for c in ai_name)
    while '__' in ai_name:
        ai_name = ai_name.replace('__', '_')
    ai_name = ai_name.strip('_-')[:32]
    
    if not ai_name:
        die(E.E003, "AI name cannot be empty after normalization")
    
    # Load or validate config exists
    try:
        cfg = load(ai_name)
        print(f"✓ Configuration loaded for '{ai_name}'", file=sys.stderr)
    except SystemExit:
        die(E.E003, f"No configuration found for '{ai_name}'. Create config file first at ~/.ai_cli_bridge/config/{ai_name}.json")
    
    # Ensure profile directory exists with correct permissions
    profile_dir = Path(cfg["_profile_dir"])
    profile_dir.mkdir(parents=True, exist_ok=True)
    profile_dir.chmod(0o700)
    
    print(f"✓ Profile directory ready: {profile_dir}", file=sys.stderr)
    print(f"\nTo use: ai-cli-bridge open {ai_name}", file=sys.stderr)
    
    return 0


================================================================================
FILE: src/ai_cli_bridge/commands/__init__.py
================================================================================

# Re-export nothing by default; keeps imports explicit in cli.py
__all__ = []



================================================================================
FILE: src/ai_cli_bridge/commands/open_cmd.py
================================================================================

import asyncio
from ..config import load, ensure_dirs
from ..lock_manager import acquire, release
from ..browser_manager import launch_browser


def run(ai_name: str, conversation: str | None, force: bool):
    """
    Open command per spec Section 8.1:
    - Lock acquire
    - Launch browser
    - (Navigation & auth readiness handled inside launch_browser)
    """
    ensure_dirs()
    cfg = load(ai_name)
    
    lock = None
    try:
        lock = acquire(ai_name, conversation, force)
        asyncio.run(_go(cfg, conversation))
        return 0
    finally:
        if lock:
            release(ai_name)

async def _go(cfg, conversation):
    # conversation is already normalized by run(); keep this as a safety net
    conversation = (conversation or "").strip() or None

    # Hand the desired conversation URL to the browser layer.
    # launch_browser() will prefer this and avoid a redundant reload if already on Claude.
    if conversation:
        cfg["_conversation_url"] = conversation

    async with launch_browser(cfg) as page:
        # Do NOT navigate here — launch_browser handles navigation (or deliberately skips it).
        print("✓ Browser launched")
        try:
            cur = page.url
        except Exception:
            cur = "(unknown)"
        print(f"✓ Loaded: {cur}")
        print("✓ Ready (auth verified)")



================================================================================
FILE: src/ai_cli_bridge/commands/send_cmd.py
================================================================================

"""
Client implementation for the 'send' command.

This module is responsible for sending a prompt to the running AI daemon
and displaying the response. It acts as a lightweight client, packaging the
user's request and sending it over HTTP.
"""
import typer
import requests
import json as json_lib  # Renamed to avoid conflict with the 'json' parameter
from typing import Optional

# Import the daemon config to know where to connect
from ..daemon import config as daemon_config

def run(
    ai_name: str,
    message: str,
    wait: bool,
    timeout: int,
    json: bool,
    debug: bool,
    # New parameters to be added in the future
    inject: Optional[str] = None,
    contextsize: Optional[int] = None,
) -> int:
    """
    Executes the 'send' command by sending a request to the daemon.
    """
    try:
        # Load daemon configuration to get host and port
        cfg = daemon_config.load_config()
        host = cfg.get("daemon", {}).get("host", "127.0.0.1")
        port = cfg.get("daemon", {}).get("port", 8000)
        daemon_url = f"http://{host}:{port}/send"

        # Construct the JSON payload for the request
        payload = {
            "target": ai_name,
            "prompt": message,
            "wait_for_response": wait,
            "timeout_s": timeout,
            # Pass along other relevant options
            "debug": debug,
            "inject": inject,
            "context_size": contextsize,
        }

        # Send the request to the daemon
        # The timeout for the request should be slightly longer than the operation timeout
        response = requests.post(daemon_url, json=payload, timeout=timeout + 10)
        response.raise_for_status()  # Raise an exception for bad status codes (4xx or 5xx)

        # Process the response from the daemon
        response_data = response.json()

        if json:
            # If --json flag is used, print the entire JSON response
            typer.echo(json_lib.dumps(response_data, indent=2))
        else:
            # Otherwise, provide a human-readable summary
            if response_data.get("success"):
                typer.secho("✓ Sent", fg=typer.colors.GREEN)
                metadata = response_data.get("metadata", {})
                snippet = response_data.get("snippet")
                
                if snippet:
                    typer.echo(f"  elapsed: {metadata.get('elapsed_ms')} ms")
                    typer.echo("  response:")
                    # CORRECTED LOGIC: Perform the replacement before the f-string
                    formatted_snippet = snippet.replace('\n', '\n    ')
                    typer.echo(f"    {formatted_snippet}")
            else:
                error_msg = response_data.get("metadata", {}).get("error", "Unknown error")
                typer.secho(f"✗ Error: {error_msg}", fg=typer.colors.RED)
                return 1

    except requests.exceptions.ConnectionError:
        typer.secho(
            "Error: Cannot connect to the AI daemon. Is it running?",
            fg=typer.colors.RED,
        )
        typer.echo("Please start it with 'ai-cli-bridge daemon start'")
        return 1
    except requests.exceptions.HTTPError as e:
        typer.secho(f"Error: Received an error response from the daemon: {e.response.status_code}", fg=typer.colors.RED)
        try:
            # Try to print the detailed error from the daemon's response
            typer.echo(e.response.json().get("detail", "No details provided."))
        except json_lib.JSONDecodeError:
            typer.echo("Could not parse error details from the daemon response.")
        return 1
    except Exception as e:
        typer.secho(f"An unexpected error occurred: {e}", fg=typer.colors.RED)
        return 1

    return 0




================================================================================
FILE: src/ai_cli_bridge/commands/status_cmd.py
================================================================================

"""Status command using AI abstraction layer."""

import asyncio
import json as jsonlib
from ..ai import AIFactory


def run(ai_name: str, json_out: bool = False) -> int:
    """
    Get status of AI session.
    
    Args:
        ai_name: AI target name (claude, chatgpt, gemini)
        json_out: Whether to output JSON format
        
    Returns:
        Exit code (0 = success, non-zero = error)
    """
    # Get AI class and its default configuration
    try:
        ai_class = AIFactory.get_class(ai_name)
        cfg = ai_class.get_default_config()
    except ValueError as e:
        if json_out:
            print(jsonlib.dumps({"ok": False, "error": "unknown_ai", "message": str(e)}, indent=2))
        else:
            print(f"✗ {e}")
        return 2
    
    try:
        ai = AIFactory.create(ai_name, cfg)
        status = asyncio.run(ai.get_status())
        
        if json_out:
            print(jsonlib.dumps(status, indent=2))
        else:
            print(f"AI Target: {status.get('ai_target', 'unknown')}")
            print(f"Connected: {status.get('connected', False)}")
            print(f"CDP Source: {status.get('cdp_source', 'none')}")
            
            if status.get('cdp_url'):
                print(f"CDP URL: {status['cdp_url']}")
            
            if status.get('last_page_url'):
                print(f"Page URL: {status['last_page_url']}")
            
            print(f"Message Count: {status.get('message_count', 0)}")
            
            if 'session_duration_s' in status:
                duration = status['session_duration_s']
                print(f"Session Duration: {duration:.1f}s")
        
        return 0
        
    except ValueError as e:
        if json_out:
            print(jsonlib.dumps({"ok": False, "error": "unknown_ai", "message": str(e)}, indent=2))
        else:
            print(f"✗ {e}")
        return 2
    except Exception as e:
        if json_out:
            print(jsonlib.dumps({"ok": False, "error": "exception", "message": str(e)}, indent=2))
        else:
            print(f"✗ Unexpected error: {e}")
        return 1


================================================================================
FILE: src/ai_cli_bridge/config.py
================================================================================

import json, re, os
from pathlib import Path
from .errors import E, die

ROOT = Path.home() / ".ai_cli_bridge"
CONF = ROOT / "config"
DEFAULT_TIMEOUTS = {
    "browser_launch": 30,
    "page_load": 30,
    "response_wait": 120,
    "file_upload": 30,
    "response_stability_ms": 2000,
}

def load(ai: str):
    p = CONF / f"{ai}.json"
    try:
        data = json.loads(p.read_text())
    except Exception as e:
        die(E.E003, f"(read {p}): {e}")

    # basic validation (FIX: correct regex with single backslash for dot)
    try:
        sv = data.get("schema_version", "1.0.0")
        if not re.match(r"^1\.[0-9]+\.[0-9]+$", sv or ""):
            raise AssertionError(f"schema_version invalid: {sv!r}")
        if not isinstance(data.get("selectors"), dict):
            raise AssertionError("selectors is not an object/dict")
        bu = data.get("base_url")
        if not (isinstance(bu, str) and bu.startswith("http")):
            raise AssertionError(f"base_url invalid: {bu!r}")
    except Exception as e:
        die(E.E003, f"(validate {p}): {e}")

    # timeouts merged with defaults
    t = {**DEFAULT_TIMEOUTS, **(data.get("timeouts") or {})}
    data["timeouts"] = t

    # profile dir
    prof = ROOT / "data" / "profiles" / ai
    prof.mkdir(parents=True, exist_ok=True)
    data["_profile_dir"] = str(prof)
    return data

def ensure_dirs():
    for d in ["config", "data/profiles", "cache/locks", "logs"]:
        (ROOT / Path(d)).mkdir(parents=True, exist_ok=True)
    for d in [ROOT, ROOT / "config", ROOT / "data", ROOT / "cache"]:
        try:
            os.chmod(d, 0o700)
        except Exception:
            pass


================================================================================
FILE: src/ai_cli_bridge/daemon/config.py
================================================================================

"""
Configuration management for the AI-CLI-Bridge Daemon.

This module defines the paths for runtime files (PID, logs, config)
and handles loading the daemon's configuration from a TOML file.
"""

import os
import pathlib
import tomli
from typing import Dict, Any

# Define the root path for all runtime data to keep the project self-contained.
# Navigate up from this file to the project root
PROJECT_ROOT = pathlib.Path(__file__).parent.parent.parent.parent.resolve()
RUNTIME_DIR = PROJECT_ROOT / "runtime"

# Define specific paths for daemon management files.
CONFIG_DIR = RUNTIME_DIR / "config"
LOG_DIR = RUNTIME_DIR / "logs"
PID_FILE = RUNTIME_DIR / "daemon.pid"
LOG_FILE = LOG_DIR / "daemon.log"
CONFIG_FILE = CONFIG_DIR / "daemon_config.toml"

# --- Default Configuration ---
# These values will be used if they are not specified in the TOML file.
DEFAULT_CONFIG = {
    "daemon": {
        "host": "127.0.0.1",
        "port": 8000,
        "log_level": "INFO",
    },
    "features": {
        "token_align_frequency": 5000,
    }
}

def load_config() -> Dict[str, Any]:
    """
    Loads the daemon configuration from the TOML file.

    If the config file does not exist, returns the default configuration.
    It merges the loaded configuration with the defaults to ensure
    all necessary keys are present.

    Returns:
        A dictionary containing the loaded and merged configuration.
    """
    # Ensure the config directory exists.
    CONFIG_DIR.mkdir(parents=True, exist_ok=True)

    config = DEFAULT_CONFIG.copy()

    if not CONFIG_FILE.exists():
        print(f"[Config] Using default configuration (no config file at: {CONFIG_FILE})")
        return config

    try:
        with open(CONFIG_FILE, "rb") as f:
            loaded_config = tomli.load(f)
            # Deep merge the loaded config into the default config
            for section, values in loaded_config.items():
                if section in config and isinstance(config[section], dict):
                    config[section].update(values)
                else:
                    config[section] = values
        print(f"[Config] Loaded configuration from: {CONFIG_FILE}")
    except tomli.TOMLDecodeError as e:
        print(f"[Config] Error decoding TOML file at {CONFIG_FILE}: {e}")
        print("[Config] Using default configuration.")
    except Exception as e:
        print(f"[Config] Error reading config file: {e}")
        print("[Config] Using default configuration.")
    
    return config


# --- Create necessary directories on import ---
def initialize_runtime_dirs():
    """
    Creates all necessary runtime directories for the daemon.
    """
    RUNTIME_DIR.mkdir(exist_ok=True)
    CONFIG_DIR.mkdir(exist_ok=True)
    LOG_DIR.mkdir(exist_ok=True)
    
    # Set restrictive permissions on runtime directory
    try:
        os.chmod(RUNTIME_DIR, 0o700)
    except Exception:
        pass


initialize_runtime_dirs()


================================================================================
FILE: src/ai_cli_bridge/daemon/daemon_cmd.py
================================================================================

"""
Typer command module for managing the AI-CLI-Bridge Daemon.

This file defines the `daemon` command group and its subcommands:
`start`, `stop`, and `status`. It uses the `process_manager` to handle the
actual lifecycle of the daemon process.
"""

import typer
import requests
from ..daemon import process_manager, config

# Create a new Typer app just for the 'daemon' subcommands
app = typer.Typer(
    help="Manage the long-running AI daemon process.",
    no_args_is_help=True
)

@app.command("start")
def start_daemon():
    """
    Start the background AI daemon.
    Initializes all AI instances and launches the browser for the session.
    """
    if process_manager.start_daemon_process():
        raise typer.Exit(0)
    else:
        raise typer.Exit(1)

@app.command("stop")
def stop_daemon():
    """
    Stop the background AI daemon.
    """
    if process_manager.stop_daemon_process():
        raise typer.Exit(0)
    else:
        raise typer.Exit(1)

@app.command("status")
def daemon_status():
    """
    Check the status of the AI daemon.
    """
    if not process_manager.is_running():
        print("Daemon status: 🛑 Not Running")
        raise typer.Exit(1)
    
    app_config = config.load_config()
    daemon_config = app_config.get("daemon", {})
    host = daemon_config.get("host", "127.0.0.1")
    port = daemon_config.get("port", 8000)
    url = f"http://{host}:{port}/status"
    
    try:
        response = requests.get(url, timeout=2)
        if response.status_code == 200:
            print("Daemon status: ✅ Running")
            # TODO: Add logic to pretty-print the JSON response from the status dashboard.
            print("\nDaemon Response:")
            print(response.json())
            return
        else:
            print(f"Daemon status: ⚠️ Responded with status {response.status_code}")
            raise typer.Exit(1)
    except requests.ConnectionError:
        print("Daemon status: 🟡 Running, but API is not responding.")
        print("   - Check logs for errors: tail -f " + str(config.LOG_FILE))
        raise typer.Exit(1)
    except Exception as e:
        print(f"An error occurred while checking status: {e}")
        raise typer.Exit(1)

# This is the entry point that the main cli.py will call
def run():
    app()



================================================================================
FILE: src/ai_cli_bridge/daemon/__init__.py
================================================================================

"""
The AI-CLI-Bridge Daemon package.

This package contains the server-side logic for managing persistent AI sessions.
"""



================================================================================
FILE: src/ai_cli_bridge/daemon/main.py
================================================================================

"""
Main entry point for the AI-CLI-Bridge Daemon.

This daemon manages persistent AI instances and serves as the bridge between
CLI commands and browser-based AI interactions. It does NOT launch the browser -
it expects an external CDP browser to already be running (via LaunchCDP.sh).

Architecture:
- Long-lived FastAPI server
- Persistent AI object instances (maintain state across requests)
- Locks to prevent concurrent access to same AI
- Connects to external CDP browser on port 9223
"""

import asyncio
import os
import signal
import time
from pathlib import Path
from typing import Dict, Any

from fastapi import FastAPI, HTTPException
from contextlib import asynccontextmanager

from ..ai.factory import AIFactory
from . import config

# ---------------------------------------------------------------------------
# Daemon State
# ---------------------------------------------------------------------------

daemon_state: Dict[str, Any] = {
    "ai_instances": {},      # Persistent AI objects {name: instance}
    "locks": {},             # Concurrency locks {name: asyncio.Lock}
    "browser_pid": None,     # Browser process ID for shutdown
}


# ---------------------------------------------------------------------------
# CDP Browser Verification (MUST BE BEFORE lifespan)
# ---------------------------------------------------------------------------

def verify_cdp_browser() -> bool:
    """
    Verify that the CDP browser is running on port 9223.
    
    Returns:
        True if browser is accessible, False otherwise
    """
    import urllib.request
    import json
    
    try:
        with urllib.request.urlopen("http://127.0.0.1:9223/json/version", timeout=2) as response:
            data = json.loads(response.read().decode())
            ws_url = data.get("webSocketDebuggerUrl")
            if ws_url and ws_url.startswith("ws://"):
                print(f"    ✓ CDP browser detected: {ws_url}")
                return True
    except Exception as e:
        print(f"    ✗ CDP browser not accessible: {e}")
    
    return False


def read_browser_pid() -> int | None:
    """
    Read the browser PID from the PID file.
    
    Returns:
        Browser PID if file exists and is valid, None otherwise
    """
    pid_file = config.PROJECT_ROOT / "runtime" / "browser.pid"
    
    if not pid_file.exists():
        return None
    
    try:
        pid = int(pid_file.read_text().strip())
        # Verify process exists
        os.kill(pid, 0)  # Signal 0 checks existence without killing
        return pid
    except (ValueError, ProcessLookupError, PermissionError):
        return None


def stop_browser(pid: int) -> None:
    """
    Gracefully stop the CDP browser process.
    
    Args:
        pid: Browser process ID
    """
    try:
        print(f"    → Stopping browser (PID: {pid})...")
        os.kill(pid, signal.SIGTERM)
        
        # Wait up to 10 seconds for graceful shutdown
        for i in range(100):
            try:
                os.kill(pid, 0)
                time.sleep(0.1)
            except ProcessLookupError:
                print("    ✓ Browser stopped gracefully")
                return
        
        # Force kill if still running
        print("    ⚠ Browser did not stop gracefully, forcing...")
        os.kill(pid, signal.SIGKILL)
        time.sleep(0.5)
        print("    ✓ Browser stopped (forced)")
        
    except ProcessLookupError:
        print("    ✓ Browser already stopped")
    except Exception as e:
        print(f"    ⚠ Error stopping browser: {e}")


# ---------------------------------------------------------------------------
# FastAPI Lifespan Management
# ---------------------------------------------------------------------------

@asynccontextmanager
async def lifespan(app: FastAPI):
    """
    Handles startup and shutdown events for the FastAPI application.
    
    Startup:
    - Verify CDP browser is running
    - Create persistent AI instances
    - Initialize locks
    
    Shutdown:
    - Stop CDP browser gracefully
    - Clean up resources
    """
    print("🚀 AI-CLI-Bridge Daemon starting up...")
    
    # Load configuration
    app_config = config.load_config()
    daemon_state["config"] = app_config
    print("    ✓ Configuration loaded")
    
    # Step 1: Verify CDP browser is running
    print("    → Verifying CDP browser...")
    if not verify_cdp_browser():
        print("\n❌ CRITICAL: CDP browser is not running on port 9223")
        print("   Please start it first:")
        print("   ./LaunchCDP.sh")
        raise RuntimeError("CDP browser not available")
    
    # Step 2: Read browser PID for later shutdown
    browser_pid = read_browser_pid()
    if browser_pid:
        daemon_state["browser_pid"] = browser_pid
        print(f"    ✓ Browser PID: {browser_pid}")
    else:
        print("    ⚠ Warning: Could not read browser PID (shutdown may not work)")
    
    # Step 3: Import all AI modules to trigger registration
    print("    → Registering AI implementations...")
    AIFactory.import_all_ais()
    available_ais = AIFactory.list_available()
    print(f"    ✓ Available AIs: {', '.join(available_ais)}")
    
    # Step 4: Create persistent AI instances
    print("    → Creating persistent AI instances...")
    for ai_name in available_ais:
        try:
            # Get AI class and its default config
            ai_class = AIFactory.get_class(ai_name)
            ai_config = ai_class.get_default_config()
            
            # Create instance
            instance = AIFactory.create(ai_name, ai_config)
            
            # Store instance and create lock
            daemon_state["ai_instances"][ai_name] = instance
            daemon_state["locks"][ai_name] = asyncio.Lock()
            
            print(f"      ✓ '{ai_name}' instance created")
            
        except Exception as e:
            print(f"      ✗ Failed to create '{ai_name}': {e}")
            # Continue with other AIs even if one fails
    
    if not daemon_state["ai_instances"]:
        print("\n❌ CRITICAL: No AI instances were created")
        raise RuntimeError("No AI instances available")
    
    print("✅ Daemon startup complete. Ready for requests.\n")
    
    # Yield control to FastAPI (server runs here)
    yield
    
    # --- Shutdown Logic ---
    print("\n🔌 AI-CLI-Bridge Daemon shutting down...")
    
    # Stop the CDP browser if we have its PID
    if daemon_state.get("browser_pid"):
        stop_browser(daemon_state["browser_pid"])
        
        # Clean up PID file
        pid_file = config.PROJECT_ROOT / "runtime" / "browser.pid"
        try:
            pid_file.unlink(missing_ok=True)
            print("    ✓ Cleaned up browser PID file")
        except Exception as e:
            print(f"    ⚠ Could not clean up PID file: {e}")
    
    print("🛑 Daemon shutdown complete.")


# ---------------------------------------------------------------------------
# FastAPI App Initialization
# ---------------------------------------------------------------------------

app = FastAPI(
    title="AI-CLI-Bridge Daemon",
    description="Manages persistent AI instances and browser interactions",
    version="2.0.0",
    lifespan=lifespan
)


# ---------------------------------------------------------------------------
# API Endpoints
# ---------------------------------------------------------------------------

@app.get("/")
async def root():
    """Root endpoint - basic health check."""
    return {
        "service": "ai-cli-bridge-daemon",
        "version": "2.0.0",
        "status": "running"
    }


@app.get("/status")
async def get_status():
    """
    Get high-level status of all managed AI instances.
    
    Returns:
        Dictionary with status of each AI instance
    """
    status = {
        "daemon": {
            "version": "2.0.0",
            "available_ais": list(daemon_state["ai_instances"].keys()),
        },
        "ais": {}
    }
    
    # Get status from each AI instance
    for ai_name, ai_instance in daemon_state["ai_instances"].items():
        try:
            ai_status = await ai_instance.get_status()
            status["ais"][ai_name] = ai_status
        except Exception as e:
            status["ais"][ai_name] = {
                "error": str(e),
                "connected": False
            }
    
    return status


@app.post("/send")
async def send_prompt_to_ai(request: dict):
    """
    Send a prompt to an AI instance.
    
    Request body:
        {
            "target": "claude",              # AI name (claude, gemini, chatgpt)
            "prompt": "Hello, world!",       # Message to send
            "wait_for_response": true,       # Wait for AI response (default: true)
            "timeout_s": 120,                # Timeout in seconds (default: 120)
            "debug": false                   # Enable debug output (default: false)
        }
    
    Returns:
        {
            "success": true,
            "snippet": "First ~280 chars of response...",
            "markdown": "Full response in markdown format",
            "metadata": {
                "turn_count": 1,
                "token_count": 150,
                "ctaw_usage_percent": 0.075,
                "elapsed_ms": 3421,
                ...
            }
        }
    """
    # Validate request
    target = request.get("target")
    prompt = request.get("prompt")
    
    if not target or not prompt:
        raise HTTPException(
            status_code=400,
            detail="Request must include 'target' and 'prompt'"
        )
    
    # Get AI instance
    ai_instance = daemon_state["ai_instances"].get(target)
    if not ai_instance:
        available = ", ".join(daemon_state["ai_instances"].keys())
        raise HTTPException(
            status_code=404,
            detail=f"AI target '{target}' not found. Available: {available}"
        )
    
    # Get lock for this AI (prevent concurrent access)
    lock = daemon_state["locks"].get(target)
    if not lock:
        raise HTTPException(
            status_code=500,
            detail=f"Internal error: lock not found for '{target}'"
        )
    
    # Set debug mode if requested
    debug = request.get("debug", False)
    if debug:
        ai_instance.set_debug(True)
    
    # Acquire lock and send prompt
    async with lock:
        try:
            success, snippet, markdown, metadata = await ai_instance.send_prompt(
                message=prompt,
                wait_for_response=request.get("wait_for_response", True),
                timeout_s=request.get("timeout_s", 120),
            )
            
            return {
                "success": success,
                "snippet": snippet,
                "markdown": markdown,
                "metadata": metadata,
            }
            
        except Exception as e:
            raise HTTPException(
                status_code=500,
                detail=f"Error during interaction: {str(e)}"
            )
        finally:
            # Reset debug mode
            if debug:
                ai_instance.set_debug(False)


@app.post("/session/new/{ai_name}")
async def new_session(ai_name: str):
    """
    Start a new chat session for the specified AI.
    
    This will reset the turn counter and token estimates.
    
    Args:
        ai_name: AI identifier (claude, gemini, chatgpt)
    
    Returns:
        Success status
    """
    ai_instance = daemon_state["ai_instances"].get(ai_name)
    if not ai_instance:
        raise HTTPException(
            status_code=404,
            detail=f"AI '{ai_name}' not found"
        )
    
    # Reset session state
    ai_instance.reset_session_state()
    
    return {
        "success": True,
        "message": f"New session started for '{ai_name}'",
        "turn_count": ai_instance.get_turn_count(),
        "token_count": ai_instance.get_token_count()
    }


# ---------------------------------------------------------------------------
# Server Entry Point
# ---------------------------------------------------------------------------

def run_daemon():
    """
    Main function to run the Uvicorn server.
    Called by: ai-cli-bridge daemon start
    """
    import uvicorn
    
    app_config = config.load_config()
    daemon_config = app_config.get("daemon", {})
    
    host = daemon_config.get("host", "127.0.0.1")
    port = daemon_config.get("port", 8000)
    log_level = daemon_config.get("log_level", "info").lower()
    
    print(f"Starting daemon on {host}:{port}")
    
    uvicorn.run(
        "ai_cli_bridge.daemon.main:app",
        host=host,
        port=port,
        log_level=log_level,
    )


if __name__ == "__main__":
    run_daemon()


================================================================================
FILE: src/ai_cli_bridge/daemon/process_manager.py
================================================================================

"""
Handles the lifecycle of the AI-CLI-Bridge daemon as a background process.

This module provides functions to start, stop, and check the status of the
daemon using a PID file to track the running process. This abstracts away
the OS-specific details of process management.
"""

import os
import signal
import subprocess
import sys
import time
from . import config

def is_running() -> bool:
    """
    Check if the daemon process is currently running.

    Returns:
        True if the PID file exists and a process with that PID is running,
        False otherwise.
    """
    if not config.PID_FILE.exists():
        return False
    
    try:
        pid = int(config.PID_FILE.read_text())
        # Sending signal 0 to a PID on Unix-like systems checks if the process
        # exists without actually sending a signal.
        os.kill(pid, 0)
    except (IOError, ValueError, OSError):
        # PID file might be corrupt, or process might not exist.
        return False
    else:
        return True

def start_daemon_process() -> bool:
    """
    Starts the daemon as a detached background process.

    It will check if the daemon is already running. If not, it spawns a new
    Python process to run the daemon's main module, redirects its output to
    a log file, and stores its PID.

    Returns:
        True if the daemon was started successfully, False otherwise.
    """
    if is_running():
        pid = config.PID_FILE.read_text()
        print(f"Daemon is already running with PID {pid}.")
        return False

    print(f"Starting daemon in the background...")
    print(f"Logs will be written to: {config.LOG_FILE}")

    # Ensure the log directory exists
    config.LOG_DIR.mkdir(parents=True, exist_ok=True)

    try:
        # Open the log file for stdout and stderr redirection
        log_file = open(config.LOG_FILE, 'a')
        
        # Command to run the daemon module
        command = [sys.executable, "-m", "ai_cli_bridge.daemon.main"]

        # Use subprocess.Popen to launch the process in the background.
        # os.setsid() is used on Unix to detach the new process from the
        # current terminal session, allowing it to continue running after
        # the parent script exits.
        process = subprocess.Popen(
            command,
            stdout=log_file,
            stderr=log_file,
            preexec_fn=os.setsid  # Detach from the terminal
        )

        # Write the new process's PID to the PID file.
        config.PID_FILE.write_text(str(process.pid))
        
        print(f"Daemon started successfully with PID {process.pid}.")
        return True
    except Exception as e:
        print(f"Error starting daemon: {e}", file=sys.stderr)
        return False

def stop_daemon_process() -> bool:
    """
    Stops the running daemon process.

    It reads the PID from the PID file and sends a termination signal
    to the process.

    Returns:
        True if the daemon was stopped successfully, False otherwise.
    """
    if not is_running():
        print("Daemon is not running.")
        return False

    try:
        pid = int(config.PID_FILE.read_text())
        print(f"Stopping daemon with PID {pid}...")
        
        # Send a SIGTERM signal to gracefully shut down the process.
        os.kill(pid, signal.SIGTERM)
        
        # Wait a moment to ensure the process has time to shut down.
        time.sleep(1)
        
        # Clean up the PID file if the process is gone.
        if not is_running():
            config.PID_FILE.unlink()
            print("Daemon stopped successfully.")
        else:
            print("Warning: Daemon process may not have shut down correctly.")
            
        return True
    except (IOError, ValueError, OSError) as e:
        print(f"Error stopping daemon: {e}", file=sys.stderr)
        # If we can't read the PID or the process is already gone,
        # just remove the stale PID file.
        if config.PID_FILE.exists():
            config.PID_FILE.unlink()
        return False



================================================================================
FILE: src/ai_cli_bridge/display.py
================================================================================

import os
def has_display(): return bool(os.environ.get("DISPLAY") or os.environ.get("WAYLAND_DISPLAY"))
def mode():
    if os.environ.get("WAYLAND_DISPLAY"): return "Wayland"
    if os.environ.get("DISPLAY"): return "X11"
    return "Unknown"


================================================================================
FILE: src/ai_cli_bridge/errors.py
================================================================================

from enum import IntEnum
class Exit(IntEnum):
    OK=0; SESSION=1; CONFIG=2; DISPLAY=3; CONCURRENCY=4; IOFS=5
class E:
    E001=("E001","No graphical display detected. AI-CLI-Bridge cannot run headless.",Exit.DISPLAY)
    E002=("E002","Browser session not found or not ready.",Exit.SESSION)
    E003=("E003","Config parse/validation error.",Exit.CONFIG)
    E004=("E004","Selector not found or invalid.",Exit.CONFIG)
    E005=("E005","Concurrent session detected.",Exit.CONCURRENCY)
def die(err, extra=None):
    code,msg,exitc = err
    if extra: msg=f"{msg} {extra}"
    print(f"{code}: {msg}")
    raise SystemExit(exitc)


================================================================================
FILE: src/ai_cli_bridge/__init__.py
================================================================================



================================================================================
FILE: src/ai_cli_bridge/lock_manager.py
================================================================================

import json, os, time
from pathlib import Path
from .errors import E, die
ROOT=Path.home()/".ai_cli_bridge"
LOCKDIR=ROOT/"cache"/"locks"
def _alive(pid:int)->bool:
    try: os.kill(pid,0); return True
    except Exception: return False
def acquire(ai:str, conversation:str|None=None, force:bool=False):
    LOCKDIR.mkdir(parents=True, exist_ok=True)
    path=LOCKDIR/f"{ai}.lock"
    if path.exists():
        try:
            data=json.loads(path.read_text()); pid=int(data.get("pid",0))
        except: pid=0
        stale = (not _alive(pid)) or (time.time()-path.stat().st_mtime>86400)
        if not stale and not force: die(E.E005)
        try: path.unlink()
        except: pass
    fd=os.open(path, os.O_CREAT|os.O_EXCL|os.O_WRONLY, 0o600)
    with os.fdopen(fd,"w") as f:
        f.write(json.dumps({
            "version":"1.0","pid":os.getpid(),
            "created_at":time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime())
        }))
    return path
def release(ai:str):
    path=LOCKDIR/f"{ai}.lock"
    try: path.unlink()
    except: pass


================================================================================
FILE: src/pyproject.toml
================================================================================

[project]
name = "ai-cli-bridge"
version = "2.0.0"
requires-python = ">=3.10"
dependencies = [
  "playwright==1.48.0",
  "typer>=0.12",
  "rich>=13.7",
  "pydantic>=2.8",
  "platformdirs>=4.0",
  "orjson>=3.9",
  "tomli",
  "requests",
  "fastapi",
  "uvicorn[standard]",
]
[project.scripts]
ai-cli-bridge = "ai_cli_bridge.cli:app"


================================================================================
FILE: src/README.md
================================================================================

# ai-cli-bridge


================================================================================
FILE: src/usermanual.md
================================================================================


# AI-CLI-Bridge — User Manual (v1.3.1)

Date: 2025-10-08  
Spec Alignment: AI-CLI-Bridge Design Specs v1.3 / Code Specs v1.3.1  
Platform: Linux (Pop!_OS 22.04 baseline). macOS/Windows may work but are not officially supported in v1.x.

---
## Table of Contents

1. What & Why
2. Architecture Overview
3. Requirements & Installation
4. Filesystem Layout
5. Configuration
    - 5.1 Schema & Example
    - 5.2 Rules, Validation, Env Overrides
6. Lock File Protocol
7. Browser Lifecycle & Auth Readiness
    - 7.1 Headed-only policy
    - 7.2 Built-in Playwright mode
    - 7.3 External Browser (CDP) mode
8. Message Block Model
    - 8.1 Discovery, Classification
    - 8.2 Extraction Semantics
9. Response Completion Detection
10. CLI Commands
    - 10.1 init
    - 10.2 open
    - 10.3 send
    - 10.4 list
    - 10.5 extract
    - 10.6 status
    - 10.7 doctor
    - 10.8 init-cdp
11. Logging & Retention
12. Error & Exit Codes
13. Security, Privacy & Disk Budget
14. Troubleshooting & FAQs
15. End-to-End Example Workflow
16. Acceptance Criteria (v1.3.1)
17. Glossary

---
## 1) What & Why

AI-CLI-Bridge lets you operate web-based AI chat UIs (Claude, ChatGPT, Gemini) from the terminal. It provides predictable, testable automation around:

- Opening/attaching to a **headed** browser session
- Sending prompts (optionally with file uploads)
- Listing/extracting response blocks (text, canvas artifacts, images)
- Health checks and diagnostics

The project intentionally forbids headless/CI because many AI UIs aggressively challenge automation; headed browsing is both more reliable and auditable.

---
## 2) Architecture Overview

- CLI (ai-cli-bridge) dispatches subcommands.
- Config (per AI) provides selectors, timeouts, base URL, CDP settings.
- Browser Manager either:
    - launches a **Playwright**-bundled Chromium persistent context, or
    - attaches to a **head**ed browser over **CDP** (Chrome DevTools Protocol).
- Auth Readiness gate ensures the page is truly usable (input present, no login/error overlays).
- Block Model discovers and classifies output elements with deterministic indexing.
- Completion Detection (Spinner + Stability) decides when a reply is “done”.
- Locking guarantees only one active session per AI profile.
- Logging & diagnostics emphasize privacy and actionable information.

---
## 3) Requirements & Installation

Required:

- Linux desktop (Wayland/X11) with a graphical session (headless forbidden).
- Python ≥ 3.10 (tested 3.12), Playwright ≥ 1.45 (tested 1.48), Chromium (tested 129).
- Network access to the target AI sites.

Typical setup:

`# venv (example) python3 -m venv ~/.ai_cli_bridge/venv source ~/.ai_cli_bridge/venv/bin/activate  pip install --upgrade pip pip install playwright typer  # One-time browser download playwright install`

---
## 4) Filesystem Layout

All data is under ~/.ai_cli_bridge/

`~/.ai_cli_bridge/
├── config/             # per-AI JSON configs (0600)
├── data/
│   └── profiles/     # per-AI browser profiles (0700)
├── cache/
│   └── locks/         # session lock files (0700)
└── logs/                # per-session logs (0600)`

Permissions:

- Directories: 0700
- Files: 0600
- If permissions are lax, the tool will auto-correct (with a warning), surfaced by doctor.

---
## 5) Configuration

### 5.1 Schema & Example

File: ~/.ai_cli_bridge/config/<AI_NAME>.json

Example (Claude):

`{
    "schema_version": "1.0.0",
    "ai_target": "claude",
     "base_url": "https://claude.ai",
     "selectors": {
          "input_box": "div[contenteditable='true']",
           "send_button": "button[aria-label='Send Message']",     "message_blocks": "div.message-content",
           "canvas_blocks": "div.artifact",
           "spinner": "div.loading-spinner",
           "image_blocks": "img.message-image",
           "file_upload_input": "input[type='file']",
           "upload_confirmation": ".file-attached",
           "login_form": "form[aria-label='Sign in']",
           "error_indicator": ".rate-limit,.error"
       },
       "timeouts": {
           "browser_launch": 30,
           "page_load": 60,
           "response_wait": 120,
           "file_upload": 30, 
           "response_stability_ms": 2000
       },
       "cdp": {
           "enable_autostart": true,
           "launcher": "playwright",             // or "flatpak"
           "port": 9223,
           "wait_seconds": 12,
           "user_data_dir": "/home/you/.ai_cli_bridge/data/profiles/claude_cdp_pw",
           "startup_urls": [
                 "https://claude.ai/chat",
            "https://chat.openai.com",
            "https://gemini.google.com"
           ]
           },
      "log_level": "info"
   }`

(Comments shown above are illustrative; JSON files must not contain comments.)

### 5.2 Rules, Validation, Env Overrides

- schema_version must be 1.x.x
- CSS selectors only (no XPath)
- Timeouts bounds:
    - browser_launch, page_load: 5–120s
    - response_wait: 10–600s
- Unknown fields → warning; ignored
- Env var overrides: flat names (e.g., AI_CLI_BRIDGE_TIMEOUT_PAGE_LOAD=45). Selectors are not overrideable by env.

---
## 6) Lock File Protocol

Path: ~/.ai_cli_bridge/cache/locks/<AI_NAME>.lock

- Atomic create: O_CREAT | O_EXCL → write JSON → fsync → close
- Format (example):
    {  
    "version": "1.0",  
    "pid": 23412,  
    "created_at": "2025-10-08T14:23:11Z",  
    "ai_target": "claude",  
    "conversation_url": "[https://claude.ai/chat/xyz123](https://claude.ai/chat/xyz123)"  
    }
- Stale if PID is dead or file > 24h old
- open --force removes stale lock and proceeds

---
## 7) Browser Lifecycle & Auth Readiness

### 7.1 Headed-only policy

- Detects $DISPLAY / $WAYLAND_DISPLAY and the compositor type.
- If forced headless, returns E001 (“cannot run headless”).
### 7.2 Built-in Playwright mode

- Uses Chromium persistent context with a user_data_dir under data/profiles/.
- Soft fingerprint-hardening (navigator.webdriver undefined, realistic UA/headers) within legal/ToS boundaries.
- Auth Readiness is satisfied when:
    1. input_box present and enabled,
    2. login_form not visible,
    3. error_indicator not visible.
- If not satisfied by page_load timeout: E002 with guidance to complete login and retry.
### 7.3 External Browser (CDP) mode

- Attaches to a running, headed browser via DevTools (CDP).
- AI_CLI_BRIDGE_CDP_URL can be exported (ws://127.0.0.1:PORT/devtools/browser/<id>).
- init-cdp can launch a CDP-enabled browser and print a ready ws:// URL.
- open will **avoid navigation** if you’re already on a Claude route; it only navigates when necessary.

Why CDP mode? It leverages your trusted headed browser profile to reduce bot challenges and preserve login state.

---
## 8) Message Block Model

### 8.1 Discovery, Classification

- Query DOM and classify with precedence:
    1. canvas_blocks
    2. image_blocks
    3. message_blocks
- If an element matches multiple roles or has nested matches, choose the highest-precedence ancestor once.
- Sort by DOM order; indices (0..N-1) are stable for the session.

### 8.2 Extraction Semantics

- text: innerText/textContent (best fidelity per target)
- canvas: raw innerHTML of the artifact container
- image: data URL (base64) if available; else src URL
- Output is the raw content only (no wrapper metadata). Text ends with trailing newline; binary/image emits bytes or data URLs.

---
## 9) Response Completion Detection

Algorithm: Spinner + Stability

1. If spinner visible → not complete
2. Once spinner absent (or never observed), start stability window:
    - Every 500ms measure (a) block count, (b) last-block DOM size
3. If either changes → reset timer
4. Mark complete when stable for response_stability_ms (e.g., 2000ms)
5. Hard deadline: response_wait. On timeout, return with a warning (command still succeeds unless the caller opts to treat timeout as error)

---
## 10) CLI Commands

Notes:

- All commands return meaningful exit codes (see Section 12).
- Timestamps in JSON outputs are ISO-8601 UTC; durations are ISO 8601 (e.g., PT1H23M45S).
### 10.1 init

Initialize AI target profile and skeleton config.

`ai-cli-bridge init <AI_NAME>`

Behavior:

- Normalize AI_NAME (lowercase, [a-z0-9_-], collapse underscores, ≤32 chars)
- Create config file and profile directory (0700)
- Idempotent

Errors:

- E003 (config create/parse), E010 (filesystem permissions)
### 10.2 open

Launch/attach and verify auth readiness.

`ai-cli-bridge open <AI_NAME> [--conversation URL] [--force]`

Behavior:

1. Display check; forbid headless (E001)
2. Acquire lock atomically; --force cleans stale locks
3. Launch Playwright persistent context or attach via CDP
4. Navigate to base_url or --conversation only if needed (avoid unnecessary reloads)
5. Verify auth readiness (3 checks)

Exit: 0 on success; first fatal error maps to exit (see Section 12).
### 10.3 send

Send a message (and optionally attach a file), then wait for completion.

`ai-cli-bridge send "MESSAGE TEXT" [--attach PATH]`

Behavior:

- Find input_box; type with human-like delays (10–50ms/char + small pauses)
- Optional attach:
    - Validate file exists, readable, < 10MB (E009 on error)
    - Use file_upload_input.set_input_files(PATH)
    - Success if upload_confirmation appears OR the file input value is set without console errors
- Click send_button
- Wait for completion using Spinner + Stability

Timeouts: file_upload, response_wait, response_stability_ms  
On response_wait timeout: exit 0 with a warning (streaming-friendly)
### 10.4 list

List discovered blocks or emit JSON.

`ai-cli-bridge list [--json] [--envelope]`

Behavior:

- Previews truncated to 60 chars on a word boundary (unicode-aware)
- --json emits a raw array; --envelope wraps in {status,timestamp,data}

Text output sample:

[0] text: "What is the capital of France?" 
[1]   text: "The capital of France is Paris. Paris has been..."
[2] canvas: "React Component - TodoApp"
[3] image: "data:image/png;base64,iVBOR..."

JSON output sample:

[
    {"index":0,"type":"text","preview":"What is the capital of France?","length":35},   {"index":1,"type":"text","preview":"The capital of France is Paris. Paris has been...","length":543},
    {"index":2,"type":"canvas","preview":"React Component - TodoApp","title":"TodoApp","length":2847}
]

### 10.5 extract

Emit the raw content of a block to stdout.

`ai-cli-bridge extract INDEX`

- Text: ends with newline
- Canvas: raw HTML
- Image: bytes or data URL

Errors: E006 (range), E007 (invalid type)
### 10.6 status

Report current session health and metadata.

`ai-cli-bridge status [--json]`

Reports:

- AI target, PID/health (2s page.title() probe), profile path
- last auth, last doctor, active conversation, lock status, session duration
- --json may include {config,data,cache,logs} disk_usage_mb and warnings

Exit: 0 if session active; 1 otherwise.
### 10.7 doctor

Validate system & target selectors.

`ai-cli-bridge doctor [--startup] [--json]`

Standard:

- Validate selectors (5s each, 3 retries), profile integrity, lock status, browser responsiveness, config schema
- Colorized output (respects --no-color / NO_COLOR)

--startup:

- Validate Python/Playwright versions, display availability & type, directory permissions (0700), config readability
- Surface auto-corrected permissions notices

Exit: 0 all good; 1 session error (standard only); 2 warnings present
### 10.8 init-cdp

Launch a CDP-enabled browser with your configured profile and startup URLs, then print a ws:// DevTools URL.

`ai-cli-bridge init-cdp <AI_NAME>`

Config (cdp block):

- launcher: "playwright" | "flatpak" (default often "flatpak")
- port: integer (e.g., 9222/9223)
- wait_seconds: how long to wait for DevTools endpoint
- user_data_dir: absolute path for the profile dir (required)
- flatpak_id: when launcher="flatpak" (e.g., io.github.ungoogled_software.ungoogled_chromium)
- startup_urls: array of tabs to open

Typical sequence:

`ai-cli-bridge init-cdp claude export AI_CLI_BRIDGE_CDP_URL="$(curl -s http://127.0.0.1:9223/json/version | jq -r .webSocketDebuggerUrl)" ai-cli-bridge open claude --conversation "https://claude.ai/chat"`

---
## 11) Logging & Retention

- One log per open; timestamps suffixed with " UTC"
- Retain 10 most recent logs; each ≤ 10 MB
- Levels: info (default), debug, trace. Message content is logged only at trace.
- Sensitive data (passwords/tokens) never logged.

---
## 12) Error & Exit Codes

| Code | Meaning                           | Exit | Action                                 |
| ---- | --------------------------------- | ---- | -------------------------------------- |
| E001 | No display / headless forbidden   | 3    | Run in graphical env; disable headless |
| E002 | Browser session not found/ready   | 1    | Run open; complete login if needed     |
| E003 | Config parse/validation error     | 2    | Fix JSON/schema; run doctor --startup  |
| E004 | Selector not found/invalid        | 2    | Update selectors; run doctor           |
| E005 | Concurrent session detected       | 4    | Close other session or use --force     |
| E006 | Index out of range                | 1    | Run list to see valid indexes          |
| E007 | Invalid block type for extraction | 1    | Verify block type with list            |
| E008 | Config version mismatch           | 2    | Update config or use compatible CLI    |
| E009 | File upload error                 | 5    | Check size/path/permissions; retry     |
| E010 | Filesystem permission error       | 5    | Fix directory perms (0700)             |

First fatal error determines exit code; warnings don’t change it.

---
## 13) Security, Privacy & Disk Budget

- Headed-only design; CI/headless forbidden.
- Profiles/cookies live under data/profiles/ (0700).
- Profiles are excluded from the ≤2GB temp/disk budget; warnings target logs/cache only.
- Sensitive data never logged; request/response bodies appear only at trace level (opt-in).

---
## 14) Troubleshooting & FAQs

• Stuck in “prove you’re human”  
– Prefer CDP mode with a trusted, headed browser profile (init-cdp). Avoid unnecessary reloads; open won’t navigate if already on a Claude route.

• Headless forbidden error (E001)  
– Ensure DISPLAY or WAYLAND_DISPLAY is set and you’re not forcing headless in config/code.

• Selectors changed after a site update  
– Run doctor; adjust selectors in your config file; re-try.

• File upload errors (E009)  
– Ensure file < 10MB; path exists; input selector is correct; wait for upload_confirmation.

• JSON output shape  
– list --json returns a raw array by default. Add --envelope to wrap responses in {status,timestamp,data}.

• Locks never clear  
– Use open --force to remove stale lock; investigate if a stray process is holding it.

---
## 15) End-to-End Example Workflow

Goal: Operate Claude via CDP with a dedicated persistent profile.

1. Configure the cdp block in ~/.ai_cli_bridge/config/claude.json:
    
    "cdp": {  
     "enable_autostart": true,  
     "launcher": "playwright",  
     "port": 9223,  
     "wait_seconds": 12,  
     "user_data_dir": "/home/you/.ai_cli_bridge/data/profiles/claude_cdp_pw",  
     "startup_urls": [  
         "[https://claude.ai/chat](https://claude.ai/chat)",  
         "[https://chat.openai.com](https://chat.openai.com)",  
         "[https://gemini.google.com](https://gemini.google.com)"  
     ]  
    }
    
2. Launch CDP browser and export ws URL:
    
    ai-cli-bridge init-cdp claude  
    export AI_CLI_BRIDGE_CDP_URL="$(curl -s [http://127.0.0.1:9223/json/version](http://127.0.0.1:9223/json/version) | jq -r .webSocketDebuggerUrl)"
    
3. Attach and verify readiness:
    
    ai-cli-bridge open claude --conversation "[https://claude.ai/chat](https://claude.ai/chat)"
    
    # ✓ Browser launched
    # ✓ Loaded: [https://claude.ai/new](https://claude.ai/new)
    # ✓ Ready (auth verified)
    
4. Operate (examples, if implemented):
    
    ai-cli-bridge send "Analyze this CSV" --attach ~/report.csv  
    ai-cli-bridge list --json  
    ai-cli-bridge extract 2 > artifact.html
    
5. Diagnostics:
    
    ai-cli-bridge doctor  
    ai-cli-bridge status --json
    
1. Shutdown:

- Close the CDP browser window (graceful). Next open will recover/clean stale locks as needed.

---
## 16) Acceptance Criteria (v1.3.1)

- Headed-only enforced (E001 on headless)
- open checks Auth Readiness (input present/enabled; no login/error overlays)
- send uses Spinner + Stability; warns (not errors) on response_wait timeout
- File uploads via set_input_files(); E009 on failure
- list --json returns raw array; --envelope available
- Locks created atomically; stale locks cleaned; force-kill on stuck shutdown after 5s
- doctor/status expose enhanced diagnostics; permission auto-fix surfaced
- Logging retention and privacy rules honored

---
## 17) Glossary

- CDP: Chrome DevTools Protocol; lets CLI attach to a running headed browser.
- Auth Readiness: Gate that ensures the UI is genuinely usable before subsequent actions.
- Block: A discovered UI element representing text, an image, or a canvas artifact.
- Spinner + Stability: Response-completion algorithm using a spinner check and a DOM stability window.
- Profile: Browser user data directory (cookies, local storage) under data/profiles/.

================================================================================
FILE: src/ai_cli_bridge/LaunchCDP.sh
================================================================================

#!/bin/bash
# Launch Playwright Chromium with session restoration

source ~/.ai_cli_bridge/venv/bin/activate

# Check if already running
if curl -s http://127.0.0.1:9223/json >/dev/null 2>&1; then
    echo "✓ CDP browser already running on port 9223"
    exit 0
fi

echo "🚀 Launching Playwright Chromium with saved session..."

CHROMIUM_PATH=$(python -c "from playwright.sync_api import sync_playwright; p = sync_playwright().start(); print(p.chromium.executable_path); p.stop()")

# CORRECT profile path - must match your existing CDP profile!
PROFILE_DIR="/home/jacques/.ai_cli_bridge/data/profiles/claude_cdp_pw"

# Ensure profile directory exists
mkdir -p "$PROFILE_DIR"

"$CHROMIUM_PATH" \
  --remote-debugging-port=9223 \
  --user-data-dir="$PROFILE_DIR" \
  --restore-last-session \
  --no-first-run \
  --no-default-browser-check &

# Wait for CDP
echo "→ Waiting for CDP..."
for i in {1..10}; do
    if curl -s http://127.0.0.1:9223/json >/dev/null 2>&1; then
        echo "✓ Browser ready!"
        break
    fi
    sleep 1
done



################################################################################
# SECTION 3: PROJECT STATISTICS
################################################################################

File Count by Type:
-------------------
Python files:    26
Config files:    2
Shell scripts:   1

Lines of Code:
--------------
 2897 total

Module Breakdown:
-----------------
ai:                  1053 lines
commands:            429 lines
daemon:              720 lines
__pycache__:         0 lines


################################################################################
# END OF SOURCE CODE DUMP
################################################################################
