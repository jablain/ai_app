================================================================================
AI-CLI-BRIDGE v2.0.0 - COMPLETE SOURCE CODE DUMP
================================================================================
Generated: Mon Oct 20 02:37:00 PM EDT 2025
Project Root: /home/jacques/dev/ai_app/ai-cli-bridge
================================================================================


################################################################################
# SECTION 1: PROJECT DIRECTORY TREE
################################################################################

.
├── gather_source.sh
├── LaunchCDP.sh
├── src
│   ├── ai_cli_bridge
│   │   ├── ai
│   │   │   ├── base.py
│   │   │   ├── chatgpt.py
│   │   │   ├── claude.py
│   │   │   ├── factory.py
│   │   │   ├── gemini.py
│   │   │   ├── __init__.py
│   │   │   └── web_base.py
│   │   ├── cli.py
│   │   ├── commands
│   │   │   ├── init_cdp_cmd.py
│   │   │   ├── __init__.py
│   │   │   ├── send_cmd.py
│   │   │   └── status_cmd.py
│   │   ├── daemon
│   │   │   ├── config.py
│   │   │   ├── daemon_cmd.py
│   │   │   ├── __init__.py
│   │   │   ├── main.py
│   │   │   └── process_manager.py
│   │   └── __init__.py
│   ├── cleanup_v1_remnant.sh
│   ├── pyproject.toml
│   ├── README.md
│   └── usermanual.md
├── src1.txt
├── src.txt
└── StopCDP.sh

5 directories, 27 files


################################################################################
# SECTION 2: SOURCE CODE FILES
################################################################################


================================================================================
FILE: src/ai_cli_bridge/ai/base.py
================================================================================

"""Abstract base class for AI interactions.

This module defines the pure interface for interacting with AI systems,
completely independent of any transport mechanism (web, API, etc.).
"""

import logging
import time
from abc import ABC, abstractmethod
from typing import Optional, Tuple, Dict, Any, List, TypedDict
from dataclasses import dataclass, field
from datetime import datetime, timezone

try:
    import tiktoken
    TIKTOKEN_AVAILABLE = True
except ImportError:
    TIKTOKEN_AVAILABLE = False

# =========================
# Type Definitions
# =========================

class AIConfig(TypedDict, total=False):
    """Configuration dictionary for AI instances."""
    ai_target: str
    max_context_tokens: int
    base_url: str  # For web-based AIs
    cdp: dict      # For web-based AIs

class AIStatus(TypedDict):
    """AI status dictionary structure."""
    ai_target: str
    turn_count: int
    token_count: int
    message_count: int
    session_duration_s: float
    last_interaction_time: Optional[float]
    ctaw_size: int
    ctaw_usage_percent: float

# =========================
# Session State
# =========================

@dataclass
class SessionState:
    """
    Encapsulates all session tracking state.
    
    This is implementation-agnostic - tracks logical operations
    without knowing HOW they're performed. Fully self-contained
    with its own CTAW tracking and usage calculation.
    """
    turn_count: int = 0
    token_count: int = 0
    message_count: int = 0
    ctaw_size: int = 200000  # Default, overridden by config
    session_start_time: float = field(default_factory=time.time)
    last_interaction_time: Optional[float] = None
    message_history: List[Dict[str, Any]] = field(default_factory=list)
    
    def add_message(self, sent_tokens: int, response_tokens: int) -> int:
        """
        Record a message exchange and return tokens used.
        
        Args:
            sent_tokens: Token count of sent message
            response_tokens: Token count of response
            
        Returns:
            Total tokens used in this exchange
        """
        self.turn_count += 1
        self.message_count += 1
        self.last_interaction_time = time.time()
        
        tokens_used = sent_tokens + response_tokens
        self.token_count += tokens_used
        
        self.message_history.append({
            "turn": self.turn_count,
            "timestamp": self.last_interaction_time,
            "sent_tokens": sent_tokens,
            "response_tokens": response_tokens,
            "tokens_used": tokens_used,
        })
        
        return tokens_used
    
    def reset(self) -> None:
        """Reset all state for a new session."""
        self.turn_count = 0
        self.token_count = 0
        self.message_count = 0
        self.session_start_time = time.time()
        self.last_interaction_time = None
        self.message_history.clear()
    
    def get_duration_s(self) -> float:
        """Get session duration in seconds."""
        return time.time() - self.session_start_time
    
    def get_ctaw_usage_percent(self) -> float:
        """
        Calculate CTAW usage as a percentage.
        
        Formula: (TokenCount / CTAWSize) * 100
        
        Returns:
            Percentage (0.0 to 100.0+)
        """
        if self.ctaw_size <= 0:
            return 0.0
        return (self.token_count / self.ctaw_size) * 100.0
    
    def to_dict(self) -> Dict[str, Any]:
        """Export state as dictionary for status reporting."""
        return {
            "turn_count": self.turn_count,
            "token_count": self.token_count,
            "message_count": self.message_count,
            "session_duration_s": round(self.get_duration_s(), 1),
            "last_interaction_time": self.last_interaction_time,
            "ctaw_size": self.ctaw_size,
            "ctaw_usage_percent": round(self.get_ctaw_usage_percent(), 2),
        }

# =========================
# Base AI Class
# =========================

class BaseAI(ABC):
    """
    Pure abstract base class for AI interactions.
    
    Defines WHAT operations are possible with an AI system,
    without specifying HOW they're implemented.
    
    Key Principles:
    - No references to transport mechanisms (CDP, HTTP, WebSocket, etc.)
    - No references to implementation details (Playwright, browsers, etc.)
    - Only logical AI operations (send message, list messages, etc.)
    - Session state tracking is implementation-agnostic
    
    Subclasses implement specific transport mechanisms:
    - WebAIBase: Browser automation via Playwright/CDP
    - APIAIBase: Direct API calls via HTTP (future)
    """
    
    def __init__(self, config: Dict[str, Any]):
        """
        Initialize base AI.
        
        Args:
            config: Configuration dict with required fields:
                - ai_target: AI identifier (e.g., 'claude', 'chatgpt')
                - max_context_tokens: Context window size
        
        Raises:
            ValueError: If required config fields are missing
        """
        # Validate required config fields
        if "ai_target" not in config:
            raise ValueError("Config must include 'ai_target'")
        if "max_context_tokens" not in config:
            raise ValueError("Config must include 'max_context_tokens'")
        
        self._config = config
        
        # Set up logging
        self._logger = logging.getLogger(f"{__name__}.{self.__class__.__name__}")
        
        # Initialize session state with CTAW size from config
        self._session = SessionState(ctaw_size=config["max_context_tokens"])
        
        # Set up tokenizer (tiktoken if available, fallback to char/4)
        self._tokenizer = None
        if TIKTOKEN_AVAILABLE:
            try:
                self._tokenizer = tiktoken.get_encoding("cl100k_base")
                self._logger.debug("Initialized tiktoken tokenizer")
            except Exception as e:
                self._logger.warning(f"Failed to initialize tiktoken: {e}")
    
    # =========================
    # Core AI Operations (Abstract Interface)
    # =========================
    
    @abstractmethod
    async def send_prompt(
        self,
        message: str,
        wait_for_response: bool = True,
        timeout_s: int = 120
    ) -> Tuple[bool, Optional[str], Optional[str], Optional[Dict[str, Any]]]:
        """
        Send a message to the AI and optionally wait for response.
        
        This is the primary interaction method. Subclasses implement
        the actual transport mechanism (web automation, API call, etc.).
        
        Args:
            message: Text to send to the AI
            wait_for_response: Whether to wait for AI's reply
            timeout_s: Maximum time to wait for response
            
        Returns:
            Tuple of (success, snippet, full_response, metadata)
            - success: True if message was sent (and response received if waiting)
            - snippet: First ~280 chars of response (for display)
            - full_response: Complete response text/markdown
            - metadata: Dict with timing, token usage, etc.
        """
        pass
    
    @abstractmethod
    async def list_messages(self) -> List[Dict[str, Any]]:
        """
        List all messages in the current conversation.
        
        Returns:
            List of message dictionaries with keys:
            - index: int (0-based)
            - type: 'user' | 'assistant' | 'system'
            - preview: str (first ~60 chars)
            - length: int (character count)
        """
        pass
    
    @abstractmethod
    async def extract_message(self, index: int) -> Optional[str]:
        """
        Extract the full content of a specific message.
        
        Args:
            index: Message index from list_messages()
            
        Returns:
            Full message content or None if not found
        """
        pass
    
    @abstractmethod
    async def start_new_session(self) -> bool:
        """
        Start a new chat session/conversation.
        
        This resets the conversation history in the AI interface
        and resets local session state tracking.
        
        Returns:
            True if new session started successfully
        """
        pass
    
    @abstractmethod
    def get_transport_status(self) -> Dict[str, Any]:
        """
        Get transport/connection status.
        
        This is implementation-specific (web has CDP info, API has endpoint info).
        Subclasses must implement this to provide transport-layer details.
        
        Returns:
            Dictionary with transport-specific status information
        """
        pass
    
    # =========================
    # AI Status (Concrete Implementation)
    # =========================
    
    def get_ai_status(self) -> AIStatus:
        """
        Get AI session status (implementation-agnostic).
        
        Returns universal AI metrics that apply regardless of
        transport mechanism (web, API, etc.).
        
        Returns:
            Dictionary with AI session information
        """
        return {
            "ai_target": self.get_ai_target(),
            **self._session.to_dict(),
        }
    
    def get_ai_target(self) -> str:
        """Get the AI target name (e.g., 'claude', 'chatgpt')."""
        return self._config.get("ai_target", "unknown")
    
    # =========================
    # Token Counting
    # =========================
    
    def _count_tokens(self, text: str) -> int:
        """
        Count tokens in text using tiktoken or fallback.
        
        Args:
            text: Text to count tokens in
            
        Returns:
            Token count
        """
        if self._tokenizer:
            try:
                return len(self._tokenizer.encode(text))
            except Exception as e:
                self._logger.warning(f"Token counting failed: {e}")
        
        # Fallback: 4 chars ≈ 1 token
        return len(text) // 4
    
    # =========================
    # Protected Helpers for Subclasses
    # =========================
    
    def _update_session_from_interaction(
        self,
        message: str,
        response: str
    ) -> Dict[str, Any]:
        """
        Update session state after a successful interaction.
        
        This is a helper method for subclasses to call after they've
        successfully completed a send_prompt operation. Returns metadata
        to be merged with transport-specific metadata.
        
        Args:
            message: The sent message
            response: The received response
            
        Returns:
            Metadata dict with session information
        """
        # Count tokens
        sent_tokens = self._count_tokens(message)
        response_tokens = self._count_tokens(response)
        
        # Update session state
        tokens_used = self._session.add_message(sent_tokens, response_tokens)
        
        # Build metadata
        metadata = {
            "timestamp": datetime.now(timezone.utc).isoformat().replace("+00:00", "Z"),
            "turn_count": self._session.turn_count,
            "message_count": self._session.message_count,
            "token_count": self._session.token_count,
            "tokens_used": tokens_used,
            "sent_tokens": sent_tokens,
            "response_tokens": response_tokens,
            "ctaw_usage_percent": round(self._session.get_ctaw_usage_percent(), 2),
            "ctaw_size": self._session.ctaw_size,
            "session_duration_s": round(self._session.get_duration_s(), 1),
        }
        
        self._logger.debug(
            f"Turn: {self._session.turn_count}, "
            f"Tokens: {self._session.token_count}, "
            f"CTAW: {self._session.get_ctaw_usage_percent():.1f}%"
        )
        
        return metadata
    
    def _reset_session_state(self) -> None:
        """
        Reset all session state (private - called by start_new_session).
        
        This clears turn counter, token counts, and message history.
        Should only be called from start_new_session() implementation.
        """
        self._logger.info("Resetting session state")
        self._session.reset()
    
    # =========================
    # Configuration Access
    # =========================
    
    def get_config(self) -> Dict[str, Any]:
        """Get the full configuration dictionary."""
        return self._config
    
    # =========================
    # Class-level Configuration
    # =========================
    
    @classmethod
    @abstractmethod
    def get_default_config(cls) -> Dict[str, Any]:
        """
        Get default configuration for this AI implementation.
        
        Returns:
            Dict with ai_target, max_context_tokens, and implementation-specific settings
        """
        pass


================================================================================
FILE: src/ai_cli_bridge/ai/chatgpt.py
================================================================================

"""ChatGPT-specific AI implementation."""

from typing import Dict, Any
from playwright.async_api import Page
from .web_base import WebAIBase
from .factory import AIFactory


class ChatGPTAI(WebAIBase):
    """ChatGPT-specific implementation using the web AI base."""
    
    # =========================
    # ChatGPT configuration
    # =========================
    
    BASE_URL = "https://chatgpt.com"
    CDP_PORT = 9223
    
    @classmethod
    def get_default_config(cls) -> Dict[str, Any]:
        """Get ChatGPT's default configuration."""
        return {
            "ai_target": "chatgpt",
            "base_url": cls.BASE_URL,
            "cdp": {"port": cls.CDP_PORT},
            "max_context_tokens": 128000  # GPT-4 Turbo context window
        }
    
    # =========================
    # ChatGPT selectors
    # =========================
    
    @property
    def INPUT_BOX(self) -> str:
        return "textarea[name='prompt-textarea']"
    
    @property
    def STOP_BUTTON(self) -> str:
        return "button[data-testid='stop-button']"
    
    @property
    def NEW_CHAT_BUTTON(self) -> str:
        return "a[data-testid='create-new-chat-button']"
    
    @property
    def RESPONSE_CONTAINER(self) -> str:
        return "div[data-message-author-role='assistant']"
    
    @property
    def RESPONSE_CONTENT(self) -> str:
        return "div.markdown.prose"
    
    # =========================
    # ChatGPT-specific overrides
    # =========================
    
    async def _ensure_chat_ready(self, page: Page) -> bool:
        """ChatGPT-specific - skip textarea visibility check."""
        # Navigate to ChatGPT if needed
        if not page.url.startswith(self._get_base_url()):
            try:
                await page.goto(self._get_base_url(), wait_until="domcontentloaded", timeout=10000)
            except Exception as e:
                self._logger.error(f"Navigation failed: {e}")
                return False
        
        # Just check if textarea exists in DOM (even if hidden)
        try:
            textarea = await page.query_selector(self.INPUT_BOX)
            return textarea is not None
        except Exception as e:
            self._logger.error(f"Input box check failed: {e}")
            return False
    
    async def _send_message(self, page: Page, message: str) -> bool:
        """ChatGPT-specific send - handle hidden textarea."""
        try:
            # ChatGPT's textarea is hidden - focus and type
            textarea = await page.query_selector(self.INPUT_BOX)
            if textarea:
                await textarea.focus()
                await page.keyboard.type(message, delay=10)
                await page.keyboard.press("Enter")
                return True
            
            return False
        except Exception as e:
            self._logger.error(f"Failed to send message: {e}")
            return False


# Register ChatGPTAI with factory
AIFactory.register("chatgpt", ChatGPTAI)


================================================================================
FILE: src/ai_cli_bridge/ai/claude.py
================================================================================

"""Claude-specific AI implementation."""

from typing import Dict, Any
from .web_base import WebAIBase
from .factory import AIFactory


class ClaudeAI(WebAIBase):
    """Claude-specific implementation using the web AI base."""
    
    # =========================
    # Claude configuration
    # =========================
    
    BASE_URL = "https://claude.ai"
    CDP_PORT = 9223
    
    @classmethod
    def get_default_config(cls) -> Dict[str, Any]:
        """Get Claude's default configuration."""
        return {
            "ai_target": "claude",
            "base_url": cls.BASE_URL,
            "cdp": {"port": cls.CDP_PORT},
            "max_context_tokens": 200000
        }
    
    # =========================
    # Claude selectors
    # =========================
    
    @property
    def INPUT_BOX(self) -> str:
        return "div[contenteditable='true']"
    
    @property
    def STOP_BUTTON(self) -> str:
        return "button[aria-label='Stop response']"
    
    @property
    def NEW_CHAT_BUTTON(self) -> str:
        return "button[aria-label*='New chat']"
    
    @property
    def RESPONSE_CONTAINER(self) -> str:
        return ".font-claude-response"
    
    @property
    def RESPONSE_CONTENT(self) -> str:
        return ".standard-markdown"


# Register ClaudeAI with factory
AIFactory.register("claude", ClaudeAI)


================================================================================
FILE: src/ai_cli_bridge/ai/factory.py
================================================================================

"""Factory for creating AI instances."""

from typing import Dict, Any
from .base import BaseAI


class AIFactory:
    """
    Factory class for creating AI instances.
    
    Manages registration and instantiation of AI implementations.
    """
    
    _registry: Dict[str, type[BaseAI]] = {}
    
    @classmethod
    def register(cls, ai_name: str, ai_class: type[BaseAI]) -> None:
        """
        Register an AI implementation.
        
        Args:
            ai_name: Lowercase AI identifier (e.g., 'claude', 'chatgpt')
            ai_class: AI class that inherits from BaseAI
        """
        normalized_name = ai_name.lower().strip()
        cls._registry[normalized_name] = ai_class
    
    
    @classmethod
    def get_class(cls, ai_name: str) -> type[BaseAI]:
        """
        Get the AI class without instantiating it.
        
        Args:
            ai_name: AI identifier (e.g., 'claude', 'chatgpt')
            
        Returns:
            The AI class (not an instance)
            
        Raises:
            ValueError: If AI name is not registered
        """
        normalized_name = ai_name.lower().strip()
        
        if normalized_name not in cls._registry:
            available = ", ".join(cls._registry.keys())
            raise ValueError(
                f"Unknown AI: '{ai_name}'. "
                f"Available: {available}"
            )
        
        return cls._registry[normalized_name]
    
    
    @classmethod
    def create(cls, ai_name: str, config: Dict[str, Any]) -> BaseAI:
        """
        Create an AI instance.
        
        Args:
            ai_name: AI identifier (e.g., 'claude', 'chatgpt')
            config: Configuration dictionary
            
        Returns:
            Instance of the appropriate AI class
            
        Raises:
            ValueError: If AI name is not registered
        """
        ai_class = cls.get_class(ai_name)
        return ai_class(config)
    
    
    @classmethod
    def list_available(cls) -> list[str]:
        """
        List all registered AI names.
        
        Returns:
            List of lowercase AI identifiers
        """
        return sorted(cls._registry.keys())
    
    
    @classmethod
    def is_registered(cls, ai_name: str) -> bool:
        """
        Check if an AI is registered.
        
        Args:
            ai_name: AI identifier
            
        Returns:
            True if registered, False otherwise
        """
        return ai_name.lower().strip() in cls._registry
    
    
    @classmethod
    def import_all_ais(cls) -> None:
        """
        Import all AI modules to trigger their registration.
        
        This must be called before using list_available() or create()
        to ensure all AI implementations are loaded.
        """
        # Import all AI implementations
        # The import statements will trigger the AIFactory.register() calls
        # at the bottom of each AI module
        try:
            from . import claude
        except ImportError as e:
            print(f"Warning: Could not import claude: {e}")
        
        try:
            from . import gemini
        except ImportError as e:
            print(f"Warning: Could not import gemini: {e}")
        
        try:
            from . import chatgpt
        except ImportError as e:
            print(f"Warning: Could not import chatgpt: {e}")


================================================================================
FILE: src/ai_cli_bridge/ai/gemini.py
================================================================================

"""Gemini-specific AI implementation."""

from typing import Dict, Any
from .web_base import WebAIBase
from .factory import AIFactory


class GeminiAI(WebAIBase):
    """Gemini-specific implementation using the web AI base."""
    
    # =========================
    # Gemini configuration
    # =========================
    
    BASE_URL = "https://gemini.google.com"
    CDP_PORT = 9223
    
    @classmethod
    def get_default_config(cls) -> Dict[str, Any]:
        """Get Gemini's default configuration."""
        return {
            "ai_target": "gemini",
            "base_url": cls.BASE_URL,
            "cdp": {"port": cls.CDP_PORT},
            "max_context_tokens": 2000000
        }
    
    # =========================
    # Gemini selectors
    # =========================
    
    @property
    def INPUT_BOX(self) -> str:
        return "div.ql-editor[aria-label*='prompt']"
    
    @property
    def STOP_BUTTON(self) -> str:
        return "button[aria-label='Stop response']"
    
    @property
    def NEW_CHAT_BUTTON(self) -> str:
        return "a.new-chat-button"
    
    @property
    def RESPONSE_CONTAINER(self) -> str:
        return "div.response-container-content"
    
    @property
    def RESPONSE_CONTENT(self) -> str:
        return "div.markdown"


# Register GeminiAI with factory
AIFactory.register("gemini", GeminiAI)


================================================================================
FILE: src/ai_cli_bridge/ai/__init__.py
================================================================================

"""AI abstraction layer for browser automation."""

from .base import BaseAI
from .factory import AIFactory

# Import AI implementations to trigger registration
from .claude import ClaudeAI
from .chatgpt import ChatGPTAI
from .gemini import GeminiAI

__all__ = ["BaseAI", "AIFactory", "ClaudeAI", "ChatGPTAI", "GeminiAI"]


================================================================================
FILE: src/ai_cli_bridge/ai/web_base.py
================================================================================

"""Base class for web-based AIs using browser automation.

This module implements the BaseAI interface using Playwright and CDP
for browser automation. All web/browser-specific logic lives here.
"""

import asyncio
import time
from abc import abstractmethod
from typing import Optional, Tuple, Dict, Any

from playwright.async_api import Page, Browser, TimeoutError as PWTimeout
from .base import BaseAI

try:
    import markdownify
except ImportError:
    markdownify = None


class BrowserConnectionPool:
    """
    Manages persistent Playwright browser connections.
    
    This should be created once at the daemon level and injected
    into WebAIBase instances to enable connection reuse.
    Includes connection health checks for reliability.
    """
    
    def __init__(self):
        self._playwright = None
        self._connections: Dict[str, Browser] = {}
        self._lock = asyncio.Lock()
    
    async def get_connection(self, ws_url: str) -> Browser:
        """
        Get or create a browser connection to the given CDP URL.
        
        Includes health check to detect and recover from stale connections.
        
        Args:
            ws_url: WebSocket URL for CDP connection
            
        Returns:
            Connected browser instance
        """
        async with self._lock:
            # Lazy-initialize Playwright
            if not self._playwright:
                from playwright.async_api import async_playwright
                self._playwright = await async_playwright().start()
            
            # Check if we have an existing connection
            browser = self._connections.get(ws_url)
            
            if browser:
                # Health check: verify connection is alive
                try:
                    _ = browser.contexts
                    return browser
                except Exception:
                    # Connection is dead, remove it
                    del self._connections[ws_url]
            
            # Create new connection
            browser = await self._playwright.chromium.connect_over_cdp(ws_url)
            self._connections[ws_url] = browser
            return browser
    
    async def close_all(self):
        """Close all connections and stop Playwright."""
        for browser in self._connections.values():
            try:
                await browser.close()
            except Exception:
                pass  # Ignore errors during cleanup
        self._connections.clear()
        
        if self._playwright:
            await self._playwright.stop()
            self._playwright = None


class WebAIBase(BaseAI):
    """
    Base class for AI implementations using web browser automation.
    
    This class adds all web-specific concepts:
    - CDP (Chrome DevTools Protocol) discovery and connection
    - Playwright browser/page management
    - DOM interaction (selectors, waiting, extraction)
    - Page navigation
    
    Subclasses must define:
    - Selector properties (INPUT_BOX, STOP_BUTTON, etc.)
    - AI-specific interaction logic (via overrides if needed)
    """
    
    # =========================
    # Common timing constants
    # =========================
    
    RESPONSE_WAIT_S = 10.0
    COMPLETION_CHECK_INTERVAL_S = 0.2
    SNIPPET_LENGTH = 280
    SNIPPET_TRIM_WINDOW = 40
    
    def __init__(self, config: Dict[str, Any]):
        """
        Initialize web-based AI.
        
        Args:
            config: Configuration dict with web-specific settings:
                - base_url: AI website URL
                - cdp: CDP configuration (port, etc.)
                - selectors: DOM selector configuration (optional)
        """
        super().__init__(config)
        
        # Web-specific state
        self._cdp_url: Optional[str] = None
        self._cdp_source: Optional[str] = None
        self._last_page_url: Optional[str] = None
        
        # CDP URL caching (60 second TTL)
        self._cdp_cache: Optional[Tuple[str, str]] = None
        self._cdp_cache_time: float = 0
        self._cdp_cache_ttl: int = 60  # seconds
        
        # Browser connection pool (injected by daemon)
        self._browser_pool: Optional[BrowserConnectionPool] = None
    
    # =========================
    # Dependency Injection
    # =========================
    
    def set_browser_pool(self, pool: BrowserConnectionPool) -> None:
        """
        Inject the browser connection pool.
        
        This should be called by the daemon after creating the AI instance.
        
        Args:
            pool: Shared BrowserConnectionPool instance
        """
        self._browser_pool = pool
    
    # =========================
    # Implementation of BaseAI Interface
    # =========================
    
    async def send_prompt(
        self,
        message: str,
        wait_for_response: bool = True,
        timeout_s: int = 120
    ) -> Tuple[bool, Optional[str], Optional[str], Optional[Dict[str, Any]]]:
        """
        Web implementation of send_prompt using browser automation.
        
        Flow:
        1. Discover/connect to browser via CDP (with caching)
        2. Get appropriate page from browser
        3. Execute web-specific interaction (type, click, wait)
        4. Extract response from DOM
        5. Update session state
        
        Args:
            message: Text to send to the AI
            wait_for_response: Whether to wait for AI's reply
            timeout_s: Maximum time to wait for response
            
        Returns:
            Tuple of (success, snippet, full_response, metadata)
        """
        # Step 1: CDP Discovery (with caching)
        ws_url, ws_source = await self._get_cdp_url()
        if not ws_url:
            self._logger.error(f"CDP discovery failed: {ws_source}")
            return False, None, None, {"error": "no_cdp", "source": ws_source}
        
        self._logger.debug(f"CDP connected via {ws_source}: {ws_url}")
        
        # Step 2: Browser Connection
        if not self._browser_pool:
            self._logger.error("No browser pool configured")
            return False, None, None, {"error": "no_browser_pool"}
        
        try:
            browser = await self._browser_pool.get_connection(ws_url)
            page = await self._pick_page(browser, self._get_base_url())
            
            if not page:
                self._logger.error("No suitable page found")
                return False, None, None, {"error": "no_page"}
            
            self._last_page_url = page.url
            self._logger.debug(f"Operating on page: {page.url}")
            
            # Step 3: Execute Web Interaction
            success, snippet, markdown, metadata = await self._execute_web_interaction(
                page, message, wait_for_response, timeout_s
            )
            
            # Step 4: Update Session State
            if success and markdown:
                session_metadata = self._update_session_from_interaction(message, markdown)
                metadata.update(session_metadata)
            
            # Add web-specific metadata
            if metadata:
                metadata["ws_source"] = ws_source
                metadata["page_url"] = page.url
            
            return success, snippet, markdown, metadata
            
        except Exception as e:
            self._logger.error(f"Error in send_prompt: {e}", exc_info=True)
            return False, None, None, {"error": "exception", "message": str(e)}
    
    def get_transport_status(self) -> Dict[str, Any]:
        """
        Get web transport status.
        
        Returns connection details specific to web automation.
        
        Returns:
            Dictionary with web transport information
        """
        return {
            "transport_type": "web",
            "connected": self._cdp_url is not None,
            "cdp_url": self._cdp_url,
            "cdp_source": self._cdp_source,
            "last_page_url": self._last_page_url,
        }
    
    async def start_new_session(self) -> bool:
        """
        Start a new chat session (web implementation).
        
        Uses the current browser connection to click the "new chat" button
        and resets the session state.
        
        Returns:
            True if new session started successfully
        """
        try:
            # Get current browser connection
            ws_url, _ = await self._get_cdp_url()
            if not ws_url or not self._browser_pool:
                self._logger.error("Cannot start new session: no browser connection")
                return False
            
            browser = await self._browser_pool.get_connection(ws_url)
            page = await self._pick_page(browser, self._get_base_url())
            
            if not page:
                self._logger.error("Cannot start new session: no page found")
                return False
            
            # Click new chat button
            button = page.locator(self.NEW_CHAT_BUTTON).first
            await button.wait_for(state="visible", timeout=5000)
            await button.click()
            
            # Wait for input box to be ready
            await page.wait_for_selector(self.INPUT_BOX, state="visible", timeout=5000)
            
            # Reset session state
            self._reset_session_state()
            
            self._logger.info("Started new session successfully")
            return True
            
        except Exception as e:
            self._logger.error(f"Failed to start new session: {e}", exc_info=True)
            return False
    
    # =========================
    # CDP Discovery & Connection (with Caching)
    # =========================
    
    async def _get_cdp_url(self) -> Tuple[Optional[str], str]:
        """
        Get CDP URL with caching to reduce HTTP probes.
        
        Cache is valid for 60 seconds, then re-discovered.
        
        Returns:
            Tuple of (ws_url or None, source: 'env'|'discovered'|'none')
        """
        now = time.time()
        
        # Return cached value if still valid
        if self._cdp_cache and (now - self._cdp_cache_time) < self._cdp_cache_ttl:
            return self._cdp_cache
        
        # Cache expired or not present, discover CDP URL
        result = await self._discover_cdp_url()
        self._cdp_cache = result
        self._cdp_cache_time = now
        
        return result
    
    async def _discover_cdp_url(self) -> Tuple[Optional[str], str]:
        """
        Discover CDP WebSocket URL.
        
        Checks:
        1. Environment variable AI_CLI_BRIDGE_CDP_URL
        2. HTTP probe to http://127.0.0.1:<port>/json/version
        
        Returns:
            Tuple of (ws_url or None, source: 'env'|'discovered'|'none')
        """
        import os
        from urllib.request import urlopen
        from urllib.error import URLError, HTTPError
        import json
        
        # Check environment variable
        env = (os.environ.get("AI_CLI_BRIDGE_CDP_URL") or "").strip()
        if env.startswith(("ws://", "wss://")) and "/devtools/browser/" in env:
            self._cdp_url = env
            self._cdp_source = "env"
            self._logger.debug(f"CDP URL from environment: {env}")
            return env, "env"
        
        # Probe HTTP endpoint
        port = self._get_cdp_port()
        url = f"http://127.0.0.1:{port}/json/version"
        
        try:
            with urlopen(url, timeout=2.0) as resp:
                data = json.loads(resp.read().decode("utf-8"))
                ws = (data.get("webSocketDebuggerUrl") or "").strip()
                if ws.startswith(("ws://", "wss://")) and "/devtools/browser/" in ws:
                    self._cdp_url = ws
                    self._cdp_source = "discovered"
                    self._logger.debug(f"CDP URL discovered: {ws}")
                    return ws, "discovered"
        except (URLError, HTTPError, TimeoutError, ValueError, json.JSONDecodeError) as e:
            self._logger.warning(f"CDP discovery failed: {e}")
        
        self._cdp_url = None
        self._cdp_source = "none"
        return None, "none"
    
    async def _pick_page(self, browser: Browser, base_url: Optional[str]) -> Optional[Page]:
        """
        Pick a page from browser contexts.
        
        Prefers pages matching base_url, else returns first page.
        
        Args:
            browser: Playwright browser instance
            base_url: Preferred base URL to match
            
        Returns:
            Page object or None
        """
        try:
            contexts = getattr(browser, "contexts", []) or []
            pages = []
            for ctx in contexts:
                pages.extend(getattr(ctx, "pages", []) or [])
            
            if base_url:
                for p in pages:
                    try:
                        if (p.url or "").startswith(base_url):
                            return p
                    except Exception:
                        continue
            
            return pages[0] if pages else None
        except Exception:
            return None
    
    # =========================
    # Configuration Helpers
    # =========================
    
    def _get_base_url(self) -> str:
        """Get base URL from config."""
        return self._config.get("base_url", "")
    
    def _get_cdp_port(self) -> int:
        """Get CDP port from config (default 9223)."""
        try:
            return int(self._config.get("cdp", {}).get("port", 9223))
        except Exception:
            return 9223
    
    # =========================
    # Abstract Selectors (must be defined by subclass)
    # =========================
    
    @property
    @abstractmethod
    def INPUT_BOX(self) -> str:
        """Selector for the message input box."""
        pass
    
    @property
    @abstractmethod
    def STOP_BUTTON(self) -> str:
        """Selector for the stop/cancel button during generation."""
        pass
    
    @property
    @abstractmethod
    def NEW_CHAT_BUTTON(self) -> str:
        """Selector for the new chat button."""
        pass
    
    @property
    @abstractmethod
    def RESPONSE_CONTAINER(self) -> str:
        """Selector for the response container element."""
        pass
    
    @property
    @abstractmethod
    def RESPONSE_CONTENT(self) -> str:
        """Selector for the actual response content within container."""
        pass
    
    # =========================
    # Web Interaction Flow
    # =========================
    
    async def _execute_web_interaction(
        self,
        page: Page,
        message: str,
        wait_for_response: bool,
        timeout_s: int
    ) -> Tuple[bool, Optional[str], Optional[str], Optional[Dict[str, Any]]]:
        """
        Execute the standard web interaction flow.
        
        Flow:
        1. Ensure chat is ready
        2. Get baseline response count
        3. Send message
        4. Wait for response completion
        5. Extract response
        
        Args:
            page: Playwright page object
            message: Message to send
            wait_for_response: Whether to wait for reply
            timeout_s: Maximum wait time
            
        Returns:
            Tuple of (success, snippet, full_markdown, metadata)
        """
        if not await self._ensure_chat_ready(page):
            return False, None, None, {"error": "chat_not_ready"}
        
        baseline_count = await self._get_response_count(page)
        
        if not await self._send_message(page, message):
            return False, None, None, {"error": "send_failed"}
        
        snippet, markdown, elapsed_ms = None, None, None
        
        if wait_for_response:
            t0 = time.time()
            
            completed = await self._wait_for_response_complete(page, timeout_s)
            
            if completed:
                snippet, markdown = await self._extract_response(page, baseline_count)
            
            elapsed_ms = int((time.time() - t0) * 1000)
        
        metadata = {
            "elapsed_ms": elapsed_ms,
            "waited": wait_for_response,
        }
        
        return True, snippet, markdown, metadata
    
    async def _ensure_chat_ready(self, page: Page) -> bool:
        """
        Ensure chat interface is ready for input.
        
        Args:
            page: Playwright page object
            
        Returns:
            True if ready, False otherwise
        """
        # Navigate if needed
        if not page.url.startswith(self._get_base_url()):
            try:
                await page.goto(
                    self._get_base_url(),
                    wait_until="domcontentloaded",
                    timeout=10000
                )
            except Exception as e:
                self._logger.error(f"Navigation failed: {e}")
                return False
        
        # Wait for input box
        try:
            await page.wait_for_selector(self.INPUT_BOX, state="visible", timeout=5000)
            return True
        except PWTimeout:
            self._logger.error("Input box not visible within timeout")
            return False
    
    async def _send_message(self, page: Page, message: str) -> bool:
        """
        Send message to the AI.
        
        Args:
            page: Playwright page object
            message: Message text to send
            
        Returns:
            True if sent successfully, False otherwise
        """
        try:
            await page.fill(self.INPUT_BOX, message, timeout=5000)
            await page.keyboard.press("Enter")
            return True
        except Exception as e:
            self._logger.error(f"Failed to send message: {e}")
            return False
    
    async def _wait_for_response_complete(self, page: Page, timeout_s: int) -> bool:
        """
        Wait for response to complete using stop-button pattern.
        
        Algorithm:
        1. Wait for stop button to appear
        2. Poll until it disappears
        3. Timeout if button stays visible too long
        
        Args:
            page: Playwright page object
            timeout_s: Maximum time to wait
            
        Returns:
            True if completion detected, False on timeout
        """
        try:
            # Wait for stop button to appear
            await page.wait_for_selector(self.STOP_BUTTON, state="visible", timeout=10000)
            
            # Poll until it disappears
            deadline = time.time() + timeout_s
            while time.time() < deadline:
                if await page.locator(self.STOP_BUTTON).count() == 0:
                    return True
                await asyncio.sleep(self.COMPLETION_CHECK_INTERVAL_S)
            
            self._logger.warning("Response timeout: stop button still visible")
            return False
        
        except PWTimeout:
            # Stop button never appeared (instant response)
            self._logger.debug("Stop button never appeared (instant response)")
            return True
        except Exception as e:
            self._logger.warning(f"Error waiting for completion: {e}")
            return True
    
    async def _extract_response(
        self,
        page: Page,
        baseline_count: int
    ) -> Tuple[Optional[str], Optional[str]]:
        """
        Extract the last response from the page.
        
        Args:
            page: Playwright page object
            baseline_count: Number of responses before sending prompt
            
        Returns:
            Tuple of (snippet, full_markdown) or (None, None)
        """
        content_sel = f"{self.RESPONSE_CONTAINER}:has({self.RESPONSE_CONTENT})"
        
        try:
            # Wait for new response
            deadline = time.time() + self.RESPONSE_WAIT_S
            while time.time() < deadline:
                if await page.locator(content_sel).count() > baseline_count:
                    break
                await asyncio.sleep(self.COMPLETION_CHECK_INTERVAL_S)
            
            # Get last response content
            last_response_content = page.locator(self.RESPONSE_CONTENT).last
            if await last_response_content.count() == 0:
                self._logger.warning("No response content found")
                return None, None
            
            html = await last_response_content.inner_html()
            if not html:
                return None, None
            
            # Convert to markdown
            if markdownify:
                markdown_text = markdownify.markdownify(html, heading_style="ATX").strip()
            else:
                markdown_text = await last_response_content.inner_text()
            
            snippet = self._create_snippet(markdown_text)
            
            return snippet, markdown_text
        
        except Exception as e:
            self._logger.error(f"Failed to extract response: {e}")
            return None, None
    
    async def _get_response_count(self, page: Page) -> int:
        """
        Get current count of response containers.
        
        Args:
            page: Playwright page object
            
        Returns:
            Number of response containers found
        """
        content_sel = f"{self.RESPONSE_CONTAINER}:has({self.RESPONSE_CONTENT})"
        try:
            return await page.locator(content_sel).count()
        except Exception:
            return 0
    
    def _create_snippet(self, text: str) -> str:
        """
        Create smart-trimmed snippet from text.
        
        Args:
            text: Full text to create snippet from
            
        Returns:
            Truncated text with ellipsis if needed
        """
        if not text:
            return ""
        
        if len(text) <= self.SNIPPET_LENGTH:
            return text
        
        cut = text[:self.SNIPPET_LENGTH]
        last_break = max(
            cut.rfind("\n"), cut.rfind(" "), cut.rfind("."),
            cut.rfind("!"), cut.rfind("?")
        )
        
        if last_break >= self.SNIPPET_LENGTH - self.SNIPPET_TRIM_WINDOW:
            return cut[:last_break].rstrip() + " …"
        
        return cut + " …"
    
    # =========================
    # Abstract stubs (not implemented for web AIs yet)
    # =========================
    
    async def list_messages(self) -> list[Dict[str, Any]]:
        """List messages - not yet implemented for web AIs."""
        raise NotImplementedError(
            f"list_messages not yet implemented for {self.__class__.__name__}"
        )
    
    async def extract_message(self, index: int) -> Optional[str]:
        """Extract message - not yet implemented for web AIs."""
        raise NotImplementedError(
            f"extract_message not yet implemented for {self.__class__.__name__}"
        )


================================================================================
FILE: src/ai_cli_bridge/cli.py
================================================================================

# ai_cli_bridge/cli.py

from __future__ import annotations
import typer

# Import only commands that still exist
from .commands.status_cmd import run as status_run
from .commands.send_cmd import run as send_run
from .commands.init_cdp_cmd import run as init_cdp_run

# Import daemon command group
from .daemon import daemon_cmd

app = typer.Typer(
    add_completion=False,
    help="ai-cli-bridge — Drive logged-in AI web UIs via CDP (Playwright).",
    no_args_is_help=True,
)

# Add daemon subcommand group
app.add_typer(daemon_cmd.app, name="daemon")

@app.command("init-cdp")
def init_cdp(
    ai_name: str = typer.Argument(..., help="Target AI (e.g., 'claude'). Launch Playwright Chromium in CDP mode."),
):
    """
    Launch Playwright Chromium with remote debugging and a persistent user data dir.
    Prints the DevTools ws URL.
    """
    raise typer.Exit(init_cdp_run(ai_name))

@app.command("send")
def send(
    ai_name: str = typer.Argument(..., help="Target AI profile (e.g., 'claude')."),
    message: str = typer.Argument(..., help="Text to send to the current conversation."),
    wait: bool = typer.Option(
        True,
        "--wait/--no-wait",
        help="Wait for assistant response and return a snippet (default: --wait).",
    ),
    timeout: int = typer.Option(
        120,
        "--timeout",
        help="Overall wait timeout in seconds (default 120; if unchanged, config.response_wait applies).",
        min=1,
    ),
    json: bool = typer.Option(
        False,
        "--json",
        help="Emit a JSON envelope (includes 'snippet' and 'markdown' when available).",
    ),
    debug: bool = typer.Option(
        False,
        "--debug",
        help="Enable debug output.",
    ),
):
    """
    Send a message to the current conversation.
    """
    raise typer.Exit(send_run(ai_name, message, wait, timeout, json, debug))

@app.command("status")
def status(
    ai_name: str = typer.Argument(..., help="Target AI profile name (e.g., 'claude')."),
    json: bool = typer.Option(False, "--json", help="Emit a JSON envelope."),
):
    """Report CDP attach, current page URL, and selector sanity for the target."""
    raise typer.Exit(status_run(ai_name, json))

@app.command("version")
def version():
    """
    Print ai-cli-bridge version.
    """
    typer.echo("ai-cli-bridge 2.0.0")

def main():
    app()

if __name__ == "__main__":
    main()


================================================================================
FILE: src/ai_cli_bridge/commands/init_cdp_cmd.py
================================================================================

# ai_cli_bridge/commands/init_cdp_cmd.py

import json
import os
import socket
import subprocess
import sys
import time
from pathlib import Path


def die(message: str, exit_code: int = 1):
    """Print error and exit."""
    print(f"Error: {message}", file=sys.stderr)
    sys.exit(exit_code)


def _is_port_open(port: int) -> bool:
    try:
        with socket.create_connection(("127.0.0.1", port), timeout=0.5):
            return True
    except OSError:
        return False


def _ensure_dir(p: str):
    d = Path(p)
    d.mkdir(parents=True, exist_ok=True)
    os.chmod(d, 0o700)


def _launch_playwright(port: int, user_data_dir: str, startup_urls: list) -> subprocess.Popen:
    """
    Launch Playwright-bundled Chromium with:
      --remote-debugging-port
      --user-data-dir
      startup URLs
    """
    _ensure_dir(user_data_dir)

    # Locate the Playwright Chromium executable
    py = (
        "from playwright.sync_api import sync_playwright; "
        "p=sync_playwright().start(); "
        "print(p.chromium.executable_path); "
        "p.stop()"
    )
    try:
        exe = subprocess.check_output(["python", "-c", py], text=True).strip()
    except Exception as e:
        die(f"Unable to locate Playwright Chromium: {e}")

    args = [
        exe,
        f"--remote-debugging-port={port}",
        f"--user-data-dir={user_data_dir}",
        "--no-first-run",
        "--new-window",
    ] + startup_urls

    return subprocess.Popen(args, stdout=subprocess.PIPE, stderr=subprocess.PIPE)


def _wait_for_ws(port: int, wait_seconds: int) -> str | None:
    """Poll /json/version until webSocketDebuggerUrl is present, or timeout."""
    import urllib.request
    deadline = time.time() + max(1, wait_seconds)
    while time.time() < deadline:
        try:
            with urllib.request.urlopen(f"http://127.0.0.1:{port}/json/version", timeout=1.5) as r:
                meta = json.loads(r.read().decode("utf-8", "ignore"))
            ws = meta.get("webSocketDebuggerUrl") or meta.get("websocketDebuggerUrl")
            if ws and ws != "null":
                return ws
        except Exception:
            pass
        time.sleep(0.4)
    return None


def run(ai_name: str) -> int:
    """
    Launch a CDP-enabled browser for the given AI and print a ws:// URL.
    Returns exit code: 0 on success, 1 on failure.
    
    V2.0.0 simplified version - uses hardcoded multi-AI setup.
    """
    # V2.0.0 hardcoded configuration
    port = 9223
    wait_seconds = 10
    
    # Project root detection
    project_root = Path.home() / "dev/ai_app/ai-cli-bridge"
    user_data_dir = str(project_root / "runtime/profiles/multi_ai_cdp")
    
    # AI-specific startup URLs
    startup_urls_map = {
        "claude": ["https://claude.ai/new"],
        "gemini": ["https://gemini.google.com/app"],
        "chatgpt": ["https://chat.openai.com/"],
    }
    
    startup_urls = startup_urls_map.get(ai_name.lower())
    if not startup_urls:
        die(f"Unknown AI: '{ai_name}'. Available: claude, gemini, chatgpt")

    # If something is already listening, don't double-launch
    proc = None
    try:
        if not _is_port_open(port):
            print("Launching CDP browser...")
            proc = _launch_playwright(port, user_data_dir, startup_urls)

        ws = _wait_for_ws(port, wait_seconds)
        if not ws:
            if proc and proc.poll() is not None:
                try:
                    _, err = proc.communicate(timeout=0.5)
                    err_txt = err.decode("utf-8", "ignore")
                except Exception:
                    err_txt = "(no stderr)"
                die(f"DevTools endpoint not available. Browser exited early.\n{err_txt}")
            die("DevTools endpoint not available. Is the browser blocked?")

        print(f"CDP ready: {ws}")
        print("Tip: export this in your shell:")
        print(f'export AI_CLI_BRIDGE_CDP_URL="{ws}"')
        return 0
    finally:
        pass


================================================================================
FILE: src/ai_cli_bridge/commands/__init__.py
================================================================================

# Re-export nothing by default; keeps imports explicit in cli.py
__all__ = []



================================================================================
FILE: src/ai_cli_bridge/commands/send_cmd.py
================================================================================

"""
Client implementation for the 'send' command.

This module is responsible for sending a prompt to the running AI daemon
and displaying the response. It acts as a lightweight client, packaging the
user's request and sending it over HTTP.
"""
import typer
import requests
import json as json_lib  # Renamed to avoid conflict with the 'json' parameter
from typing import Optional

# Import the daemon config to know where to connect
from ..daemon import config as daemon_config

def run(
    ai_name: str,
    message: str,
    wait: bool,
    timeout: int,
    json: bool,
    debug: bool,
    # New parameters to be added in the future
    inject: Optional[str] = None,
    contextsize: Optional[int] = None,
) -> int:
    """
    Executes the 'send' command by sending a request to the daemon.
    """
    try:
        # Load daemon configuration to get host and port
        cfg = daemon_config.load_config()
        host = cfg.get("daemon", {}).get("host", "127.0.0.1")
        port = cfg.get("daemon", {}).get("port", 8000)
        daemon_url = f"http://{host}:{port}/send"

        # Construct the JSON payload for the request
        payload = {
            "target": ai_name,
            "prompt": message,
            "wait_for_response": wait,
            "timeout_s": timeout,
            # Pass along other relevant options
            "debug": debug,
            "inject": inject,
            "context_size": contextsize,
        }

        # Send the request to the daemon
        # The timeout for the request should be slightly longer than the operation timeout
        response = requests.post(daemon_url, json=payload, timeout=timeout + 10)
        response.raise_for_status()  # Raise an exception for bad status codes (4xx or 5xx)

        # Process the response from the daemon
        response_data = response.json()

        if json:
            # If --json flag is used, print the entire JSON response
            typer.echo(json_lib.dumps(response_data, indent=2))
        else:
            # Otherwise, provide a human-readable summary
            if response_data.get("success"):
                typer.secho("✓ Sent", fg=typer.colors.GREEN)
                metadata = response_data.get("metadata", {})
                snippet = response_data.get("snippet")
                
                if snippet:
                    typer.echo(f"  elapsed: {metadata.get('elapsed_ms')} ms")
                    typer.echo("  response:")
                    # CORRECTED LOGIC: Perform the replacement before the f-string
                    formatted_snippet = snippet.replace('\n', '\n    ')
                    typer.echo(f"    {formatted_snippet}")
            else:
                error_msg = response_data.get("metadata", {}).get("error", "Unknown error")
                typer.secho(f"✗ Error: {error_msg}", fg=typer.colors.RED)
                return 1

    except requests.exceptions.ConnectionError:
        typer.secho(
            "Error: Cannot connect to the AI daemon. Is it running?",
            fg=typer.colors.RED,
        )
        typer.echo("Please start it with 'ai-cli-bridge daemon start'")
        return 1
    except requests.exceptions.HTTPError as e:
        typer.secho(f"Error: Received an error response from the daemon: {e.response.status_code}", fg=typer.colors.RED)
        try:
            # Try to print the detailed error from the daemon's response
            typer.echo(e.response.json().get("detail", "No details provided."))
        except json_lib.JSONDecodeError:
            typer.echo("Could not parse error details from the daemon response.")
        return 1
    except Exception as e:
        typer.secho(f"An unexpected error occurred: {e}", fg=typer.colors.RED)
        return 1

    return 0




================================================================================
FILE: src/ai_cli_bridge/commands/status_cmd.py
================================================================================

"""Status command using AI abstraction layer."""

import asyncio
import json as jsonlib
from ..ai import AIFactory


def run(ai_name: str, json_out: bool = False) -> int:
    """
    Get status of AI session.
    
    Args:
        ai_name: AI target name (claude, chatgpt, gemini)
        json_out: Whether to output JSON format
        
    Returns:
        Exit code (0 = success, non-zero = error)
    """
    # Get AI class and its default configuration
    try:
        ai_class = AIFactory.get_class(ai_name)
        cfg = ai_class.get_default_config()
    except ValueError as e:
        if json_out:
            print(jsonlib.dumps({"ok": False, "error": "unknown_ai", "message": str(e)}, indent=2))
        else:
            print(f"✗ {e}")
        return 2
    
    try:
        ai = AIFactory.create(ai_name, cfg)
        status = asyncio.run(ai.get_status())
        
        if json_out:
            print(jsonlib.dumps(status, indent=2))
        else:
            print(f"AI Target: {status.get('ai_target', 'unknown')}")
            print(f"Connected: {status.get('connected', False)}")
            print(f"CDP Source: {status.get('cdp_source', 'none')}")
            
            if status.get('cdp_url'):
                print(f"CDP URL: {status['cdp_url']}")
            
            if status.get('last_page_url'):
                print(f"Page URL: {status['last_page_url']}")
            
            print(f"Message Count: {status.get('message_count', 0)}")
            
            if 'session_duration_s' in status:
                duration = status['session_duration_s']
                print(f"Session Duration: {duration:.1f}s")
        
        return 0
        
    except ValueError as e:
        if json_out:
            print(jsonlib.dumps({"ok": False, "error": "unknown_ai", "message": str(e)}, indent=2))
        else:
            print(f"✗ {e}")
        return 2
    except Exception as e:
        if json_out:
            print(jsonlib.dumps({"ok": False, "error": "exception", "message": str(e)}, indent=2))
        else:
            print(f"✗ Unexpected error: {e}")
        return 1


================================================================================
FILE: src/ai_cli_bridge/daemon/config.py
================================================================================

"""
Configuration management for the AI-CLI-Bridge Daemon.

This module defines the paths for runtime files (PID, logs, config)
and handles loading the daemon's configuration from a TOML file.
"""

import os
import pathlib
import tomli
from typing import Dict, Any

# Define the root path for all runtime data to keep the project self-contained.
# Navigate up from this file to the project root
PROJECT_ROOT = pathlib.Path(__file__).parent.parent.parent.parent.resolve()
RUNTIME_DIR = PROJECT_ROOT / "runtime"

# Define specific paths for daemon management files.
CONFIG_DIR = RUNTIME_DIR / "config"
LOG_DIR = RUNTIME_DIR / "logs"
PID_FILE = RUNTIME_DIR / "daemon.pid"
LOG_FILE = LOG_DIR / "daemon.log"
CONFIG_FILE = CONFIG_DIR / "daemon_config.toml"

# --- Default Configuration ---
# These values will be used if they are not specified in the TOML file.
DEFAULT_CONFIG = {
    "daemon": {
        "host": "127.0.0.1",
        "port": 8000,
        "log_level": "INFO",
    },
    "features": {
        "token_align_frequency": 5000,
    }
}

def load_config() -> Dict[str, Any]:
    """
    Loads the daemon configuration from the TOML file.

    If the config file does not exist, returns the default configuration.
    It merges the loaded configuration with the defaults to ensure
    all necessary keys are present.

    Returns:
        A dictionary containing the loaded and merged configuration.
    """
    # Ensure the config directory exists.
    CONFIG_DIR.mkdir(parents=True, exist_ok=True)

    config = DEFAULT_CONFIG.copy()

    if not CONFIG_FILE.exists():
        print(f"[Config] Using default configuration (no config file at: {CONFIG_FILE})")
        return config

    try:
        with open(CONFIG_FILE, "rb") as f:
            loaded_config = tomli.load(f)
            # Deep merge the loaded config into the default config
            for section, values in loaded_config.items():
                if section in config and isinstance(config[section], dict):
                    config[section].update(values)
                else:
                    config[section] = values
        print(f"[Config] Loaded configuration from: {CONFIG_FILE}")
    except tomli.TOMLDecodeError as e:
        print(f"[Config] Error decoding TOML file at {CONFIG_FILE}: {e}")
        print("[Config] Using default configuration.")
    except Exception as e:
        print(f"[Config] Error reading config file: {e}")
        print("[Config] Using default configuration.")
    
    return config


# --- Create necessary directories on import ---
def initialize_runtime_dirs():
    """
    Creates all necessary runtime directories for the daemon.
    """
    RUNTIME_DIR.mkdir(exist_ok=True)
    CONFIG_DIR.mkdir(exist_ok=True)
    LOG_DIR.mkdir(exist_ok=True)
    
    # Set restrictive permissions on runtime directory
    try:
        os.chmod(RUNTIME_DIR, 0o700)
    except Exception:
        pass


initialize_runtime_dirs()


================================================================================
FILE: src/ai_cli_bridge/daemon/daemon_cmd.py
================================================================================

"""
Typer command module for managing the AI-CLI-Bridge Daemon.

This file defines the `daemon` command group and its subcommands:
`start`, `stop`, and `status`. It uses the `process_manager` to handle the
actual lifecycle of the daemon process.
"""

import typer
import requests
from ..daemon import process_manager, config

# Create a new Typer app just for the 'daemon' subcommands
app = typer.Typer(
    help="Manage the long-running AI daemon process.",
    no_args_is_help=True
)

@app.command("start")
def start_daemon():
    """
    Start the background AI daemon.
    Initializes all AI instances and launches the browser for the session.
    """
    if process_manager.start_daemon_process():
        raise typer.Exit(0)
    else:
        raise typer.Exit(1)

@app.command("stop")
def stop_daemon():
    """
    Stop the background AI daemon.
    """
    if process_manager.stop_daemon_process():
        raise typer.Exit(0)
    else:
        raise typer.Exit(1)

@app.command("status")
def daemon_status():
    """
    Check the status of the AI daemon.
    """
    if not process_manager.is_running():
        print("Daemon status: 🛑 Not Running")
        raise typer.Exit(1)
    
    app_config = config.load_config()
    daemon_config = app_config.get("daemon", {})
    host = daemon_config.get("host", "127.0.0.1")
    port = daemon_config.get("port", 8000)
    url = f"http://{host}:{port}/status"
    
    try:
        response = requests.get(url, timeout=2)
        if response.status_code == 200:
            print("Daemon status: ✅ Running")
            # TODO: Add logic to pretty-print the JSON response from the status dashboard.
            print("\nDaemon Response:")
            print(response.json())
            return
        else:
            print(f"Daemon status: ⚠️ Responded with status {response.status_code}")
            raise typer.Exit(1)
    except requests.ConnectionError:
        print("Daemon status: 🟡 Running, but API is not responding.")
        print("   - Check logs for errors: tail -f " + str(config.LOG_FILE))
        raise typer.Exit(1)
    except Exception as e:
        print(f"An error occurred while checking status: {e}")
        raise typer.Exit(1)

# This is the entry point that the main cli.py will call
def run():
    app()



================================================================================
FILE: src/ai_cli_bridge/daemon/__init__.py
================================================================================

"""
The AI-CLI-Bridge Daemon package.

This package contains the server-side logic for managing persistent AI sessions.
"""



================================================================================
FILE: src/ai_cli_bridge/daemon/main.py
================================================================================

"""
Main entry point for the AI-CLI-Bridge Daemon (Final Refactored Version).

Key features:
- Browser connection pool created once and injected into AI instances
- Web-specific dependencies properly isolated
- Clean separation between BaseAI interface and WebAI implementation
- Separate AI status and transport status endpoints
- Standard Python logging configured at startup
"""

import asyncio
import logging
import os
import signal
import time
from pathlib import Path
from typing import Dict, Any

from fastapi import FastAPI, HTTPException
from contextlib import asynccontextmanager

from ..ai.factory import AIFactory
from ..ai.web_base import BrowserConnectionPool, WebAIBase
from . import config

# ---------------------------------------------------------------------------
# Daemon State
# ---------------------------------------------------------------------------

daemon_state: Dict[str, Any] = {
    "ai_instances": {},           # Persistent AI objects {name: instance}
    "locks": {},                  # Concurrency locks {name: asyncio.Lock}
    "browser_pool": None,         # Shared browser connection pool
    "browser_pid": None,          # Browser process ID for shutdown
}


# ---------------------------------------------------------------------------
# CDP Browser Verification
# ---------------------------------------------------------------------------

def verify_cdp_browser() -> bool:
    """Verify that the CDP browser is running on port 9223."""
    import urllib.request
    import json
    
    try:
        with urllib.request.urlopen("http://127.0.0.1:9223/json/version", timeout=2) as response:
            data = json.loads(response.read().decode())
            ws_url = data.get("webSocketDebuggerUrl")
            if ws_url and ws_url.startswith("ws://"):
                print(f"    ✓ CDP browser detected: {ws_url}")
                return True
    except Exception as e:
        print(f"    ✗ CDP browser not accessible: {e}")
    
    return False


def read_browser_pid() -> int | None:
    """Read the browser PID from the PID file."""
    pid_file = config.PROJECT_ROOT / "runtime" / "browser.pid"
    
    if not pid_file.exists():
        return None
    
    try:
        pid = int(pid_file.read_text().strip())
        os.kill(pid, 0)  # Verify process exists
        return pid
    except (ValueError, ProcessLookupError, PermissionError):
        return None


def stop_browser(pid: int) -> None:
    """Gracefully stop the CDP browser process."""
    try:
        print(f"    → Stopping browser (PID: {pid})...")
        os.kill(pid, signal.SIGTERM)
        
        # Wait up to 10 seconds for graceful shutdown
        for i in range(100):
            try:
                os.kill(pid, 0)
                time.sleep(0.1)
            except ProcessLookupError:
                print("    ✓ Browser stopped gracefully")
                return
        
        # Force kill if still running
        print("    ⚠ Browser did not stop gracefully, forcing...")
        os.kill(pid, signal.SIGKILL)
        time.sleep(0.5)
        print("    ✓ Browser stopped (forced)")
        
    except ProcessLookupError:
        print("    ✓ Browser already stopped")
    except Exception as e:
        print(f"    ⚠ Error stopping browser: {e}")


# ---------------------------------------------------------------------------
# FastAPI Lifespan Management
# ---------------------------------------------------------------------------

@asynccontextmanager
async def lifespan(app: FastAPI):
    """
    Handles startup and shutdown events for the FastAPI application.
    
    Startup:
    - Configure logging
    - Verify CDP browser is running
    - Create shared browser connection pool
    - Create persistent AI instances
    - Inject browser pool into web-based AIs
    
    Shutdown:
    - Close all browser connections
    - Stop CDP browser gracefully
    """
    print("🚀 AI-CLI-Bridge Daemon starting up...")
    
    # Step 0: Configure logging
    app_config = config.load_config()
    log_level = app_config.get("daemon", {}).get("log_level", "INFO").upper()
    logging.basicConfig(
        level=getattr(logging, log_level, logging.INFO),
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    logger = logging.getLogger(__name__)
    logger.info("Logging configured")
    
    # Load configuration
    daemon_state["config"] = app_config
    print("    ✓ Configuration loaded")
    
    # Step 1: Verify CDP browser is running
    print("    → Verifying CDP browser...")
    if not verify_cdp_browser():
        print("\n❌ CRITICAL: CDP browser is not running on port 9223")
        print("   Please start it first:")
        print("   ./LaunchCDP.sh")
        raise RuntimeError("CDP browser not available")
    
    # Step 2: Read browser PID for later shutdown
    browser_pid = read_browser_pid()
    if browser_pid:
        daemon_state["browser_pid"] = browser_pid
        print(f"    ✓ Browser PID: {browser_pid}")
    else:
        print("    ⚠ Warning: Could not read browser PID (shutdown may not work)")
    
    # Step 3: Create shared browser connection pool
    print("    → Creating browser connection pool...")
    daemon_state["browser_pool"] = BrowserConnectionPool()
    print("    ✓ Browser connection pool created")
    
    # Step 4: Import all AI modules to trigger registration
    print("    → Registering AI implementations...")
    AIFactory.import_all_ais()
    available_ais = AIFactory.list_available()
    print(f"    ✓ Available AIs: {', '.join(available_ais)}")
    
    # Step 5: Create persistent AI instances
    print("    → Creating persistent AI instances...")
    for ai_name in available_ais:
        try:
            # Get AI class and its default config
            ai_class = AIFactory.get_class(ai_name)
            ai_config = ai_class.get_default_config()
            
            # Create instance
            instance = AIFactory.create(ai_name, ai_config)
            
            # Inject browser pool if this is a web-based AI
            if isinstance(instance, WebAIBase):
                instance.set_browser_pool(daemon_state["browser_pool"])
                print(f"      ✓ '{ai_name}' instance created (web-based)")
            else:
                print(f"      ✓ '{ai_name}' instance created (API-based)")
            
            # Store instance and create lock
            daemon_state["ai_instances"][ai_name] = instance
            daemon_state["locks"][ai_name] = asyncio.Lock()
            
        except Exception as e:
            logger.error(f"Failed to create '{ai_name}': {e}", exc_info=True)
            print(f"      ✗ Failed to create '{ai_name}': {e}")
            # Continue with other AIs even if one fails
    
    if not daemon_state["ai_instances"]:
        print("\n❌ CRITICAL: No AI instances were created")
        raise RuntimeError("No AI instances available")
    
    print("✅ Daemon startup complete. Ready for requests.\n")
    
    # Yield control to FastAPI (server runs here)
    yield
    
    # --- Shutdown Logic ---
    print("\n🔌 AI-CLI-Bridge Daemon shutting down...")
    
    # Close browser connection pool
    if daemon_state["browser_pool"]:
        print("    → Closing browser connections...")
        await daemon_state["browser_pool"].close_all()
        print("    ✓ Browser connections closed")
    
    # Stop the CDP browser if we have its PID
    if daemon_state.get("browser_pid"):
        stop_browser(daemon_state["browser_pid"])
        
        # Clean up PID file
        pid_file = config.PROJECT_ROOT / "runtime" / "browser.pid"
        try:
            pid_file.unlink(missing_ok=True)
            print("    ✓ Cleaned up browser PID file")
        except Exception as e:
            print(f"    ⚠ Could not clean up PID file: {e}")
    
    print("🛑 Daemon shutdown complete.")


# ---------------------------------------------------------------------------
# FastAPI App Initialization
# ---------------------------------------------------------------------------

app = FastAPI(
    title="AI-CLI-Bridge Daemon",
    description="Manages persistent AI instances and browser interactions",
    version="2.0.0",
    lifespan=lifespan
)


# ---------------------------------------------------------------------------
# API Endpoints
# ---------------------------------------------------------------------------

@app.get("/")
async def root():
    """Root endpoint - basic health check."""
    return {
        "service": "ai-cli-bridge-daemon",
        "version": "2.0.0",
        "status": "running",
        "architecture": "clean_separation_v2"
    }


@app.get("/status")
async def get_status():
    """
    Get high-level status of all managed AI instances.
    
    Returns separate AI status and transport status for clean separation.
    """
    status = {
        "daemon": {
            "version": "2.0.0",
            "available_ais": list(daemon_state["ai_instances"].keys()),
            "browser_pool_active": daemon_state["browser_pool"] is not None,
        },
        "ais": {}
    }
    
    # Get status from each AI instance
    for ai_name, ai_instance in daemon_state["ai_instances"].items():
        try:
            # Combine AI status and transport status
            ai_status = ai_instance.get_ai_status()
            transport_status = ai_instance.get_transport_status()
            
            status["ais"][ai_name] = {
                **ai_status,
                **transport_status,
            }
        except Exception as e:
            logging.getLogger(__name__).error(
                f"Error getting status for {ai_name}: {e}",
                exc_info=True
            )
            status["ais"][ai_name] = {
                "error": str(e),
                "connected": False
            }
    
    return status


@app.post("/send")
async def send_prompt_to_ai(request: dict):
    """
    Send a prompt to an AI instance.
    
    Request body:
        {
            "target": "claude",              # AI name
            "prompt": "Hello, world!",       # Message to send
            "wait_for_response": true,       # Wait for AI response
            "timeout_s": 120,                # Timeout in seconds
            "debug": false                   # Enable debug output
        }
    """
    logger = logging.getLogger(__name__)
    
    # Validate request
    target = request.get("target")
    prompt = request.get("prompt")
    
    if not target or not prompt:
        raise HTTPException(
            status_code=400,
            detail="Request must include 'target' and 'prompt'"
        )
    
    # Get AI instance
    ai_instance = daemon_state["ai_instances"].get(target)
    if not ai_instance:
        available = ", ".join(daemon_state["ai_instances"].keys())
        raise HTTPException(
            status_code=404,
            detail=f"AI target '{target}' not found. Available: {available}"
        )
    
    # Get lock for this AI (prevent concurrent access)
    lock = daemon_state["locks"].get(target)
    if not lock:
        raise HTTPException(
            status_code=500,
            detail=f"Internal error: lock not found for '{target}'"
        )
    
    # Acquire lock and send prompt
    async with lock:
        try:
            success, snippet, markdown, metadata = await ai_instance.send_prompt(
                message=prompt,
                wait_for_response=request.get("wait_for_response", True),
                timeout_s=request.get("timeout_s", 120),
            )
            
            return {
                "success": success,
                "snippet": snippet,
                "markdown": markdown,
                "metadata": metadata,
            }
            
        except Exception as e:
            logger.error(f"Error during interaction with {target}: {e}", exc_info=True)
            raise HTTPException(
                status_code=500,
                detail=f"Error during interaction: {str(e)}"
            )


@app.post("/session/new/{ai_name}")
async def new_session(ai_name: str):
    """Start a new chat session for the specified AI."""
    logger = logging.getLogger(__name__)
    
    ai_instance = daemon_state["ai_instances"].get(ai_name)
    if not ai_instance:
        raise HTTPException(
            status_code=404,
            detail=f"AI '{ai_name}' not found"
        )
    
    try:
        success = await ai_instance.start_new_session()
        
        if success:
            ai_status = ai_instance.get_ai_status()
            return {
                "success": True,
                "message": f"New session started for '{ai_name}'",
                **ai_status,
            }
        else:
            raise HTTPException(
                status_code=500,
                detail=f"Failed to start new session for '{ai_name}'"
            )
    except Exception as e:
        logger.error(f"Error starting new session for {ai_name}: {e}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail=f"Error starting new session: {str(e)}"
        )


# ---------------------------------------------------------------------------
# Server Entry Point
# ---------------------------------------------------------------------------

def run_daemon():
    """
    Main function to run the Uvicorn server.
    Called by: ai-cli-bridge daemon start
    """
    import uvicorn
    
    app_config = config.load_config()
    daemon_config = app_config.get("daemon", {})
    
    host = daemon_config.get("host", "127.0.0.1")
    port = daemon_config.get("port", 8000)
    log_level = daemon_config.get("log_level", "info").lower()
    
    print(f"Starting daemon on {host}:{port}")
    
    uvicorn.run(
        "ai_cli_bridge.daemon.main:app",
        host=host,
        port=port,
        log_level=log_level,
    )


if __name__ == "__main__":
    run_daemon()


================================================================================
FILE: src/ai_cli_bridge/daemon/process_manager.py
================================================================================

"""
Handles the lifecycle of the AI-CLI-Bridge daemon as a background process.

This module provides functions to start, stop, and check the status of the
daemon using a PID file to track the running process. This abstracts away
the OS-specific details of process management.
"""

import os
import signal
import subprocess
import sys
import time
from . import config

def is_running() -> bool:
    """
    Check if the daemon process is currently running.

    Returns:
        True if the PID file exists and a process with that PID is running,
        False otherwise.
    """
    if not config.PID_FILE.exists():
        return False
    
    try:
        pid = int(config.PID_FILE.read_text())
        # Sending signal 0 to a PID on Unix-like systems checks if the process
        # exists without actually sending a signal.
        os.kill(pid, 0)
    except (IOError, ValueError, OSError):
        # PID file might be corrupt, or process might not exist.
        return False
    else:
        return True

def start_daemon_process() -> bool:
    """
    Starts the daemon as a detached background process.

    It will check if the daemon is already running. If not, it spawns a new
    Python process to run the daemon's main module, redirects its output to
    a log file, and stores its PID.

    Returns:
        True if the daemon was started successfully, False otherwise.
    """
    if is_running():
        pid = config.PID_FILE.read_text()
        print(f"Daemon is already running with PID {pid}.")
        return False

    print(f"Starting daemon in the background...")
    print(f"Logs will be written to: {config.LOG_FILE}")

    # Ensure the log directory exists
    config.LOG_DIR.mkdir(parents=True, exist_ok=True)

    try:
        # Open the log file for stdout and stderr redirection
        log_file = open(config.LOG_FILE, 'a')
        
        # Command to run the daemon module
        command = [sys.executable, "-m", "ai_cli_bridge.daemon.main"]

        # Use subprocess.Popen to launch the process in the background.
        # os.setsid() is used on Unix to detach the new process from the
        # current terminal session, allowing it to continue running after
        # the parent script exits.
        process = subprocess.Popen(
            command,
            stdout=log_file,
            stderr=log_file,
            preexec_fn=os.setsid  # Detach from the terminal
        )

        # Write the new process's PID to the PID file.
        config.PID_FILE.write_text(str(process.pid))
        
        print(f"Daemon started successfully with PID {process.pid}.")
        return True
    except Exception as e:
        print(f"Error starting daemon: {e}", file=sys.stderr)
        return False

def stop_daemon_process() -> bool:
    """
    Stops the running daemon process.

    It reads the PID from the PID file and sends a termination signal
    to the process.

    Returns:
        True if the daemon was stopped successfully, False otherwise.
    """
    if not is_running():
        print("Daemon is not running.")
        return False

    try:
        pid = int(config.PID_FILE.read_text())
        print(f"Stopping daemon with PID {pid}...")
        
        # Send a SIGTERM signal to gracefully shut down the process.
        os.kill(pid, signal.SIGTERM)
        
        # Wait a moment to ensure the process has time to shut down.
        time.sleep(1)
        
        # Clean up the PID file if the process is gone.
        if not is_running():
            config.PID_FILE.unlink()
            print("Daemon stopped successfully.")
        else:
            print("Warning: Daemon process may not have shut down correctly.")
            
        return True
    except (IOError, ValueError, OSError) as e:
        print(f"Error stopping daemon: {e}", file=sys.stderr)
        # If we can't read the PID or the process is already gone,
        # just remove the stale PID file.
        if config.PID_FILE.exists():
            config.PID_FILE.unlink()
        return False



================================================================================
FILE: src/ai_cli_bridge/__init__.py
================================================================================



================================================================================
FILE: src/pyproject.toml
================================================================================

[project]
name = "ai-cli-bridge"
version = "2.0.0"
requires-python = ">=3.10"
dependencies = [
  "playwright==1.48.0",
  "typer>=0.12",
  "rich>=13.7",
  "pydantic>=2.8",
  "platformdirs>=4.0",
  "orjson>=3.9",
  "tomli",
  "requests",
  "fastapi",
  "uvicorn[standard]",
]
[project.scripts]
ai-cli-bridge = "ai_cli_bridge.cli:app"


================================================================================
FILE: src/README.md
================================================================================

# ai-cli-bridge


================================================================================
FILE: src/usermanual.md
================================================================================


# AI-CLI-Bridge — User Manual (v1.3.1)

Date: 2025-10-08  
Spec Alignment: AI-CLI-Bridge Design Specs v1.3 / Code Specs v1.3.1  
Platform: Linux (Pop!_OS 22.04 baseline). macOS/Windows may work but are not officially supported in v1.x.

---
## Table of Contents

1. What & Why
2. Architecture Overview
3. Requirements & Installation
4. Filesystem Layout
5. Configuration
    - 5.1 Schema & Example
    - 5.2 Rules, Validation, Env Overrides
6. Lock File Protocol
7. Browser Lifecycle & Auth Readiness
    - 7.1 Headed-only policy
    - 7.2 Built-in Playwright mode
    - 7.3 External Browser (CDP) mode
8. Message Block Model
    - 8.1 Discovery, Classification
    - 8.2 Extraction Semantics
9. Response Completion Detection
10. CLI Commands
    - 10.1 init
    - 10.2 open
    - 10.3 send
    - 10.4 list
    - 10.5 extract
    - 10.6 status
    - 10.7 doctor
    - 10.8 init-cdp
11. Logging & Retention
12. Error & Exit Codes
13. Security, Privacy & Disk Budget
14. Troubleshooting & FAQs
15. End-to-End Example Workflow
16. Acceptance Criteria (v1.3.1)
17. Glossary

---
## 1) What & Why

AI-CLI-Bridge lets you operate web-based AI chat UIs (Claude, ChatGPT, Gemini) from the terminal. It provides predictable, testable automation around:

- Opening/attaching to a **headed** browser session
- Sending prompts (optionally with file uploads)
- Listing/extracting response blocks (text, canvas artifacts, images)
- Health checks and diagnostics

The project intentionally forbids headless/CI because many AI UIs aggressively challenge automation; headed browsing is both more reliable and auditable.

---
## 2) Architecture Overview

- CLI (ai-cli-bridge) dispatches subcommands.
- Config (per AI) provides selectors, timeouts, base URL, CDP settings.
- Browser Manager either:
    - launches a **Playwright**-bundled Chromium persistent context, or
    - attaches to a **head**ed browser over **CDP** (Chrome DevTools Protocol).
- Auth Readiness gate ensures the page is truly usable (input present, no login/error overlays).
- Block Model discovers and classifies output elements with deterministic indexing.
- Completion Detection (Spinner + Stability) decides when a reply is “done”.
- Locking guarantees only one active session per AI profile.
- Logging & diagnostics emphasize privacy and actionable information.

---
## 3) Requirements & Installation

Required:

- Linux desktop (Wayland/X11) with a graphical session (headless forbidden).
- Python ≥ 3.10 (tested 3.12), Playwright ≥ 1.45 (tested 1.48), Chromium (tested 129).
- Network access to the target AI sites.

Typical setup:

`# venv (example) python3 -m venv ~/.ai_cli_bridge/venv source ~/.ai_cli_bridge/venv/bin/activate  pip install --upgrade pip pip install playwright typer  # One-time browser download playwright install`

---
## 4) Filesystem Layout

All data is under ~/.ai_cli_bridge/

`~/.ai_cli_bridge/
├── config/             # per-AI JSON configs (0600)
├── data/
│   └── profiles/     # per-AI browser profiles (0700)
├── cache/
│   └── locks/         # session lock files (0700)
└── logs/                # per-session logs (0600)`

Permissions:

- Directories: 0700
- Files: 0600
- If permissions are lax, the tool will auto-correct (with a warning), surfaced by doctor.

---
## 5) Configuration

### 5.1 Schema & Example

File: ~/.ai_cli_bridge/config/<AI_NAME>.json

Example (Claude):

`{
    "schema_version": "1.0.0",
    "ai_target": "claude",
     "base_url": "https://claude.ai",
     "selectors": {
          "input_box": "div[contenteditable='true']",
           "send_button": "button[aria-label='Send Message']",     "message_blocks": "div.message-content",
           "canvas_blocks": "div.artifact",
           "spinner": "div.loading-spinner",
           "image_blocks": "img.message-image",
           "file_upload_input": "input[type='file']",
           "upload_confirmation": ".file-attached",
           "login_form": "form[aria-label='Sign in']",
           "error_indicator": ".rate-limit,.error"
       },
       "timeouts": {
           "browser_launch": 30,
           "page_load": 60,
           "response_wait": 120,
           "file_upload": 30, 
           "response_stability_ms": 2000
       },
       "cdp": {
           "enable_autostart": true,
           "launcher": "playwright",             // or "flatpak"
           "port": 9223,
           "wait_seconds": 12,
           "user_data_dir": "/home/you/.ai_cli_bridge/data/profiles/claude_cdp_pw",
           "startup_urls": [
                 "https://claude.ai/chat",
            "https://chat.openai.com",
            "https://gemini.google.com"
           ]
           },
      "log_level": "info"
   }`

(Comments shown above are illustrative; JSON files must not contain comments.)

### 5.2 Rules, Validation, Env Overrides

- schema_version must be 1.x.x
- CSS selectors only (no XPath)
- Timeouts bounds:
    - browser_launch, page_load: 5–120s
    - response_wait: 10–600s
- Unknown fields → warning; ignored
- Env var overrides: flat names (e.g., AI_CLI_BRIDGE_TIMEOUT_PAGE_LOAD=45). Selectors are not overrideable by env.

---
## 6) Lock File Protocol

Path: ~/.ai_cli_bridge/cache/locks/<AI_NAME>.lock

- Atomic create: O_CREAT | O_EXCL → write JSON → fsync → close
- Format (example):
    {  
    "version": "1.0",  
    "pid": 23412,  
    "created_at": "2025-10-08T14:23:11Z",  
    "ai_target": "claude",  
    "conversation_url": "[https://claude.ai/chat/xyz123](https://claude.ai/chat/xyz123)"  
    }
- Stale if PID is dead or file > 24h old
- open --force removes stale lock and proceeds

---
## 7) Browser Lifecycle & Auth Readiness

### 7.1 Headed-only policy

- Detects $DISPLAY / $WAYLAND_DISPLAY and the compositor type.
- If forced headless, returns E001 (“cannot run headless”).
### 7.2 Built-in Playwright mode

- Uses Chromium persistent context with a user_data_dir under data/profiles/.
- Soft fingerprint-hardening (navigator.webdriver undefined, realistic UA/headers) within legal/ToS boundaries.
- Auth Readiness is satisfied when:
    1. input_box present and enabled,
    2. login_form not visible,
    3. error_indicator not visible.
- If not satisfied by page_load timeout: E002 with guidance to complete login and retry.
### 7.3 External Browser (CDP) mode

- Attaches to a running, headed browser via DevTools (CDP).
- AI_CLI_BRIDGE_CDP_URL can be exported (ws://127.0.0.1:PORT/devtools/browser/<id>).
- init-cdp can launch a CDP-enabled browser and print a ready ws:// URL.
- open will **avoid navigation** if you’re already on a Claude route; it only navigates when necessary.

Why CDP mode? It leverages your trusted headed browser profile to reduce bot challenges and preserve login state.

---
## 8) Message Block Model

### 8.1 Discovery, Classification

- Query DOM and classify with precedence:
    1. canvas_blocks
    2. image_blocks
    3. message_blocks
- If an element matches multiple roles or has nested matches, choose the highest-precedence ancestor once.
- Sort by DOM order; indices (0..N-1) are stable for the session.

### 8.2 Extraction Semantics

- text: innerText/textContent (best fidelity per target)
- canvas: raw innerHTML of the artifact container
- image: data URL (base64) if available; else src URL
- Output is the raw content only (no wrapper metadata). Text ends with trailing newline; binary/image emits bytes or data URLs.

---
## 9) Response Completion Detection

Algorithm: Spinner + Stability

1. If spinner visible → not complete
2. Once spinner absent (or never observed), start stability window:
    - Every 500ms measure (a) block count, (b) last-block DOM size
3. If either changes → reset timer
4. Mark complete when stable for response_stability_ms (e.g., 2000ms)
5. Hard deadline: response_wait. On timeout, return with a warning (command still succeeds unless the caller opts to treat timeout as error)

---
## 10) CLI Commands

Notes:

- All commands return meaningful exit codes (see Section 12).
- Timestamps in JSON outputs are ISO-8601 UTC; durations are ISO 8601 (e.g., PT1H23M45S).
### 10.1 init

Initialize AI target profile and skeleton config.

`ai-cli-bridge init <AI_NAME>`

Behavior:

- Normalize AI_NAME (lowercase, [a-z0-9_-], collapse underscores, ≤32 chars)
- Create config file and profile directory (0700)
- Idempotent

Errors:

- E003 (config create/parse), E010 (filesystem permissions)
### 10.2 open

Launch/attach and verify auth readiness.

`ai-cli-bridge open <AI_NAME> [--conversation URL] [--force]`

Behavior:

1. Display check; forbid headless (E001)
2. Acquire lock atomically; --force cleans stale locks
3. Launch Playwright persistent context or attach via CDP
4. Navigate to base_url or --conversation only if needed (avoid unnecessary reloads)
5. Verify auth readiness (3 checks)

Exit: 0 on success; first fatal error maps to exit (see Section 12).
### 10.3 send

Send a message (and optionally attach a file), then wait for completion.

`ai-cli-bridge send "MESSAGE TEXT" [--attach PATH]`

Behavior:

- Find input_box; type with human-like delays (10–50ms/char + small pauses)
- Optional attach:
    - Validate file exists, readable, < 10MB (E009 on error)
    - Use file_upload_input.set_input_files(PATH)
    - Success if upload_confirmation appears OR the file input value is set without console errors
- Click send_button
- Wait for completion using Spinner + Stability

Timeouts: file_upload, response_wait, response_stability_ms  
On response_wait timeout: exit 0 with a warning (streaming-friendly)
### 10.4 list

List discovered blocks or emit JSON.

`ai-cli-bridge list [--json] [--envelope]`

Behavior:

- Previews truncated to 60 chars on a word boundary (unicode-aware)
- --json emits a raw array; --envelope wraps in {status,timestamp,data}

Text output sample:

[0] text: "What is the capital of France?" 
[1]   text: "The capital of France is Paris. Paris has been..."
[2] canvas: "React Component - TodoApp"
[3] image: "data:image/png;base64,iVBOR..."

JSON output sample:

[
    {"index":0,"type":"text","preview":"What is the capital of France?","length":35},   {"index":1,"type":"text","preview":"The capital of France is Paris. Paris has been...","length":543},
    {"index":2,"type":"canvas","preview":"React Component - TodoApp","title":"TodoApp","length":2847}
]

### 10.5 extract

Emit the raw content of a block to stdout.

`ai-cli-bridge extract INDEX`

- Text: ends with newline
- Canvas: raw HTML
- Image: bytes or data URL

Errors: E006 (range), E007 (invalid type)
### 10.6 status

Report current session health and metadata.

`ai-cli-bridge status [--json]`

Reports:

- AI target, PID/health (2s page.title() probe), profile path
- last auth, last doctor, active conversation, lock status, session duration
- --json may include {config,data,cache,logs} disk_usage_mb and warnings

Exit: 0 if session active; 1 otherwise.
### 10.7 doctor

Validate system & target selectors.

`ai-cli-bridge doctor [--startup] [--json]`

Standard:

- Validate selectors (5s each, 3 retries), profile integrity, lock status, browser responsiveness, config schema
- Colorized output (respects --no-color / NO_COLOR)

--startup:

- Validate Python/Playwright versions, display availability & type, directory permissions (0700), config readability
- Surface auto-corrected permissions notices

Exit: 0 all good; 1 session error (standard only); 2 warnings present
### 10.8 init-cdp

Launch a CDP-enabled browser with your configured profile and startup URLs, then print a ws:// DevTools URL.

`ai-cli-bridge init-cdp <AI_NAME>`

Config (cdp block):

- launcher: "playwright" | "flatpak" (default often "flatpak")
- port: integer (e.g., 9222/9223)
- wait_seconds: how long to wait for DevTools endpoint
- user_data_dir: absolute path for the profile dir (required)
- flatpak_id: when launcher="flatpak" (e.g., io.github.ungoogled_software.ungoogled_chromium)
- startup_urls: array of tabs to open

Typical sequence:

`ai-cli-bridge init-cdp claude export AI_CLI_BRIDGE_CDP_URL="$(curl -s http://127.0.0.1:9223/json/version | jq -r .webSocketDebuggerUrl)" ai-cli-bridge open claude --conversation "https://claude.ai/chat"`

---
## 11) Logging & Retention

- One log per open; timestamps suffixed with " UTC"
- Retain 10 most recent logs; each ≤ 10 MB
- Levels: info (default), debug, trace. Message content is logged only at trace.
- Sensitive data (passwords/tokens) never logged.

---
## 12) Error & Exit Codes

| Code | Meaning                           | Exit | Action                                 |
| ---- | --------------------------------- | ---- | -------------------------------------- |
| E001 | No display / headless forbidden   | 3    | Run in graphical env; disable headless |
| E002 | Browser session not found/ready   | 1    | Run open; complete login if needed     |
| E003 | Config parse/validation error     | 2    | Fix JSON/schema; run doctor --startup  |
| E004 | Selector not found/invalid        | 2    | Update selectors; run doctor           |
| E005 | Concurrent session detected       | 4    | Close other session or use --force     |
| E006 | Index out of range                | 1    | Run list to see valid indexes          |
| E007 | Invalid block type for extraction | 1    | Verify block type with list            |
| E008 | Config version mismatch           | 2    | Update config or use compatible CLI    |
| E009 | File upload error                 | 5    | Check size/path/permissions; retry     |
| E010 | Filesystem permission error       | 5    | Fix directory perms (0700)             |

First fatal error determines exit code; warnings don’t change it.

---
## 13) Security, Privacy & Disk Budget

- Headed-only design; CI/headless forbidden.
- Profiles/cookies live under data/profiles/ (0700).
- Profiles are excluded from the ≤2GB temp/disk budget; warnings target logs/cache only.
- Sensitive data never logged; request/response bodies appear only at trace level (opt-in).

---
## 14) Troubleshooting & FAQs

• Stuck in “prove you’re human”  
– Prefer CDP mode with a trusted, headed browser profile (init-cdp). Avoid unnecessary reloads; open won’t navigate if already on a Claude route.

• Headless forbidden error (E001)  
– Ensure DISPLAY or WAYLAND_DISPLAY is set and you’re not forcing headless in config/code.

• Selectors changed after a site update  
– Run doctor; adjust selectors in your config file; re-try.

• File upload errors (E009)  
– Ensure file < 10MB; path exists; input selector is correct; wait for upload_confirmation.

• JSON output shape  
– list --json returns a raw array by default. Add --envelope to wrap responses in {status,timestamp,data}.

• Locks never clear  
– Use open --force to remove stale lock; investigate if a stray process is holding it.

---
## 15) End-to-End Example Workflow

Goal: Operate Claude via CDP with a dedicated persistent profile.

1. Configure the cdp block in ~/.ai_cli_bridge/config/claude.json:
    
    "cdp": {  
     "enable_autostart": true,  
     "launcher": "playwright",  
     "port": 9223,  
     "wait_seconds": 12,  
     "user_data_dir": "/home/you/.ai_cli_bridge/data/profiles/claude_cdp_pw",  
     "startup_urls": [  
         "[https://claude.ai/chat](https://claude.ai/chat)",  
         "[https://chat.openai.com](https://chat.openai.com)",  
         "[https://gemini.google.com](https://gemini.google.com)"  
     ]  
    }
    
2. Launch CDP browser and export ws URL:
    
    ai-cli-bridge init-cdp claude  
    export AI_CLI_BRIDGE_CDP_URL="$(curl -s [http://127.0.0.1:9223/json/version](http://127.0.0.1:9223/json/version) | jq -r .webSocketDebuggerUrl)"
    
3. Attach and verify readiness:
    
    ai-cli-bridge open claude --conversation "[https://claude.ai/chat](https://claude.ai/chat)"
    
    # ✓ Browser launched
    # ✓ Loaded: [https://claude.ai/new](https://claude.ai/new)
    # ✓ Ready (auth verified)
    
4. Operate (examples, if implemented):
    
    ai-cli-bridge send "Analyze this CSV" --attach ~/report.csv  
    ai-cli-bridge list --json  
    ai-cli-bridge extract 2 > artifact.html
    
5. Diagnostics:
    
    ai-cli-bridge doctor  
    ai-cli-bridge status --json
    
1. Shutdown:

- Close the CDP browser window (graceful). Next open will recover/clean stale locks as needed.

---
## 16) Acceptance Criteria (v1.3.1)

- Headed-only enforced (E001 on headless)
- open checks Auth Readiness (input present/enabled; no login/error overlays)
- send uses Spinner + Stability; warns (not errors) on response_wait timeout
- File uploads via set_input_files(); E009 on failure
- list --json returns raw array; --envelope available
- Locks created atomically; stale locks cleaned; force-kill on stuck shutdown after 5s
- doctor/status expose enhanced diagnostics; permission auto-fix surfaced
- Logging retention and privacy rules honored

---
## 17) Glossary

- CDP: Chrome DevTools Protocol; lets CLI attach to a running headed browser.
- Auth Readiness: Gate that ensures the UI is genuinely usable before subsequent actions.
- Block: A discovered UI element representing text, an image, or a canvas artifact.
- Spinner + Stability: Response-completion algorithm using a spinner check and a DOM stability window.
- Profile: Browser user data directory (cookies, local storage) under data/profiles/.


################################################################################
# SECTION 3: PROJECT STATISTICS
################################################################################

File Count by Type:
-------------------
Python files:    18
Config files:    2
Shell scripts:   1

Lines of Code:
--------------
 2522 total

Module Breakdown:
-----------------
ai:                  1414 lines
commands:            298 lines
daemon:              727 lines
__pycache__:         0 lines


################################################################################
# END OF SOURCE CODE DUMP
################################################################################
